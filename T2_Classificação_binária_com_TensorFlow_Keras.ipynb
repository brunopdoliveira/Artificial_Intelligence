{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019f3c45",
   "metadata": {},
   "source": [
    "# Trabalho #2 - Classificação binária com TensorFlow Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c940f0",
   "metadata": {},
   "source": [
    "## Coloque o seu nome e RA:\n",
    "\n",
    "Aluno: Bruno Pinto de Oliveira\n",
    "\n",
    "RA: 21.84712-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65eb33",
   "metadata": {},
   "source": [
    "Nesse trabalho será desenvolvido uma rede neural usando a plataforma TensorFlow-Keras, para realizar uma tarefa de classificação binária. O conjunto de dados utilizado é o \" Red Wine Quality\", que pode ser obtido no Kaggle no link (https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009).\n",
    "\n",
    "Esse conjunto de dados contém características de diversos vinhos tintos e para cada um deles fornece uma pontuação de 0 a 10. Quanto maior a pontuação melhor é a qualidade do vinho. As características fornecidos dos vinhos descrevem algumas de suas propriedades relacionadas à  sua qualidade.\n",
    "\n",
    "O intuito é somente classificar os vinhos como sendo bons ou ruins. Vamos considerar que um vinho é ruim se a sua pontuação for menor ou igual a 5 e que um vinho é bom se a sua pontuação for maior do que 5. Assim, você deve processar a coluna que fornece a qualidade dos vinhos de forma a criar duas classes: vinho ruim => classe 0 (nota <=5); vinho bom => classe 1 (nota >5). Após criar essas duas classes você deve remover dos dados a coluna com a pontuação dos vinhos.\n",
    "\n",
    "Além de criar a saída desejada, será normalizadas as características que possuem intervalos de variação muito grandes. \n",
    "\n",
    "Ao término, apresenareie pelo menos os seguintes resultados:\n",
    "\n",
    "1. Resultado do processo de treinamento (gráficos);\n",
    "\n",
    "2. Valores da função de custo e da métrica para os dados de treinamento e teste (use o método evaluate);\n",
    "\n",
    "3. Gráfico com as classes previstas junto com as classes reais dos dados de teste. Use círculos de cores diferentes para diferenciar as classe previstas das reais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f7eea7",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Importado bibliotecas que serão utilizada no trabalho vigente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9bd8bb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd                                  #biblioteca python que processa arquivos tabulados\n",
    "from sklearn.model_selection import train_test_split #divide conjunto de dados\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11c557",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "Lendo arquivo .csv e atribuindo em 'df' (Data frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a8fb0df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality-red.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c9de7c",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "Apenas para verificação, foi impresso os tipos de dados dos elemento compostos em 'df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "dfba6471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           float64\n",
       "volatile acidity        float64\n",
       "citric acid             float64\n",
       "residual sugar          float64\n",
       "chlorides               float64\n",
       "free sulfur dioxide     float64\n",
       "total sulfur dioxide    float64\n",
       "density                 float64\n",
       "pH                      float64\n",
       "sulphates               float64\n",
       "alcohol                 float64\n",
       "quality                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d0e6f",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "Verificação se possui dados divergentes ou nulos no Data frame calculando estatísticas básicas dos dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "a6382368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>8.319637</td>\n",
       "      <td>1.741096</td>\n",
       "      <td>4.60000</td>\n",
       "      <td>7.1000</td>\n",
       "      <td>7.90000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>15.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.52000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual sugar</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>2.20000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>15.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.07900</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.61100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>72.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>289.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.99007</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>1.00369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>2.74000</td>\n",
       "      <td>3.2100</td>\n",
       "      <td>3.31000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.62000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>8.40000</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>10.20000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>14.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>5.636023</td>\n",
       "      <td>0.807569</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count       mean        std      min      25%  \\\n",
       "fixed acidity         1599.0   8.319637   1.741096  4.60000   7.1000   \n",
       "volatile acidity      1599.0   0.527821   0.179060  0.12000   0.3900   \n",
       "citric acid           1599.0   0.270976   0.194801  0.00000   0.0900   \n",
       "residual sugar        1599.0   2.538806   1.409928  0.90000   1.9000   \n",
       "chlorides             1599.0   0.087467   0.047065  0.01200   0.0700   \n",
       "free sulfur dioxide   1599.0  15.874922  10.460157  1.00000   7.0000   \n",
       "total sulfur dioxide  1599.0  46.467792  32.895324  6.00000  22.0000   \n",
       "density               1599.0   0.996747   0.001887  0.99007   0.9956   \n",
       "pH                    1599.0   3.311113   0.154386  2.74000   3.2100   \n",
       "sulphates             1599.0   0.658149   0.169507  0.33000   0.5500   \n",
       "alcohol               1599.0  10.422983   1.065668  8.40000   9.5000   \n",
       "quality               1599.0   5.636023   0.807569  3.00000   5.0000   \n",
       "\n",
       "                           50%        75%        max  \n",
       "fixed acidity          7.90000   9.200000   15.90000  \n",
       "volatile acidity       0.52000   0.640000    1.58000  \n",
       "citric acid            0.26000   0.420000    1.00000  \n",
       "residual sugar         2.20000   2.600000   15.50000  \n",
       "chlorides              0.07900   0.090000    0.61100  \n",
       "free sulfur dioxide   14.00000  21.000000   72.00000  \n",
       "total sulfur dioxide  38.00000  62.000000  289.00000  \n",
       "density                0.99675   0.997835    1.00369  \n",
       "pH                     3.31000   3.400000    4.01000  \n",
       "sulphates              0.62000   0.730000    2.00000  \n",
       "alcohol               10.20000  11.100000   14.90000  \n",
       "quality                6.00000   6.000000    8.00000  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae41bb",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "\n",
    "Substituição do nome da coluna 'quality' por 'old_quality'. Posteriormente é adicionado uma coluna com o nome de 'quality' no Data frame. É verificado na coluna 'old_quality' os dados, se menor ou igual a 5, valor 1, caso não, valor 0. Essa matriz de 0 e 1 é atribuido a coluna 'quality'. Por fim, é retirado do Data frame a coluna 'old_quality' e impresso os 10 primeiro elemente da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7a0b595f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "5            7.4              0.66         0.00             1.8      0.075   \n",
       "6            7.9              0.60         0.06             1.6      0.069   \n",
       "7            7.3              0.65         0.00             1.2      0.065   \n",
       "8            7.8              0.58         0.02             2.0      0.073   \n",
       "9            7.5              0.50         0.36             6.1      0.071   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                 17.0                 102.0   0.9978  3.35       0.80   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        1  \n",
       "1      9.8        1  \n",
       "2      9.8        1  \n",
       "3      9.8        0  \n",
       "4      9.4        1  \n",
       "5      9.4        1  \n",
       "6      9.4        1  \n",
       "7     10.0        0  \n",
       "8      9.5        0  \n",
       "9     10.5        1  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'quality': 'old_quality'})\n",
    "df[\"quality\"] = np.where(df.old_quality <= 5, 1, 0)\n",
    "df = df.drop(columns=['old_quality'])\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe57372",
   "metadata": {},
   "source": [
    "## Step 6\n",
    "\n",
    "Criação dos dados de teste e dado de treinamento, sendo dividido em 80% de treinamento e 20% de teste. Como padrão, é realizado o embaralhamento pelo comando 'shuffle'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ae094060",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907b020",
   "metadata": {},
   "source": [
    "## Step 7\n",
    "\n",
    "Atribuição dos dados de treinamento e teste da matriz de saída. O comando '.pop' permite retirar do Data frame a coluna 'quality', transforma-o em um vetor e atribuí em Y_train e Y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "1dacaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(train_df.pop('quality')) \n",
    "Y_test = np.array(test_df.pop('quality'))\n",
    "\n",
    "#não se pode fornecer um data frame (df) para a entrada da rede, por isso transfama-o em um tensor (array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74e607",
   "metadata": {},
   "source": [
    "## Step 8\n",
    "\n",
    "Apenas para verificação, foi impresso os 5 primeiros dados de treinamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "1f6726c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.080</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.99624</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.85</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.079</td>\n",
       "      <td>24.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.090</td>\n",
       "      <td>16.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>11.9</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.068</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99880</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.68</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.066</td>\n",
       "      <td>15.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.99470</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.78</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1141            8.2             0.380         0.32            2.50      0.080   \n",
       "1421            7.5             0.400         0.18            1.60      0.079   \n",
       "135             8.4             0.745         0.11            1.90      0.090   \n",
       "441            11.9             0.400         0.65            2.15      0.068   \n",
       "1230            7.7             0.180         0.34            2.70      0.066   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1141                 24.0                  71.0  0.99624  3.27       0.85   \n",
       "1421                 24.0                  58.0  0.99650  3.34       0.58   \n",
       "135                  16.0                  63.0  0.99650  3.19       0.82   \n",
       "441                   7.0                  27.0  0.99880  3.06       0.68   \n",
       "1230                 15.0                  58.0  0.99470  3.37       0.78   \n",
       "\n",
       "      alcohol  \n",
       "1141     11.0  \n",
       "1421      9.4  \n",
       "135       9.6  \n",
       "441      11.3  \n",
       "1230     11.8  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2545d4bf",
   "metadata": {},
   "source": [
    "## Step 9\n",
    "\n",
    "Normalização dos valores que possui alta taxa de variação. É de extrema importância inicializar a RNA com valores pequenos. Para todos os dados que possui alta variação, foi-se calculado a média e desvio padrão.\n",
    "\n",
    "*DADOS DE TREINAMENTO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "87f7522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fixed_acidity = train_df['fixed acidity'].mean()                  #calcula media\n",
    "std_fixed_acidity = train_df['fixed acidity'].std()                    #calcula desvio padrão\n",
    "\n",
    "mean_residual_sugar = train_df['residual sugar'].mean()                #calcula media\n",
    "std_residual_sugar = train_df['residual sugar'].std()                  #calcula desvio padrão\n",
    "\n",
    "mean_free_sulfur_dioxide = train_df['free sulfur dioxide'].mean()      #calcula media\n",
    "std_free_sulfur_dioxide = train_df['free sulfur dioxide'].std()        #calcula desvio padrão\n",
    "\n",
    "mean_total_sulfur_dioxide = train_df['total sulfur dioxide'].mean()    #calcula media\n",
    "std_total_sulfur_dioxide = train_df['total sulfur dioxide'].std()      #calcula desvio padrão\n",
    "\n",
    "mean_alcohol = train_df['alcohol'].mean()                              #calcula media\n",
    "std_alcohol = train_df['alcohol'].std()                                #calcula desvio padrão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e07bd02",
   "metadata": {},
   "source": [
    "## Step 10\n",
    "\n",
    "Calculo de normalização, subtraindo os dado reais de treinamento pela média dos dados e subtraindo pelo desvio padrão.\n"
   ]
  },
  {
   "attachments": {
    "desvio.PNG": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKsAAABMCAYAAAASqUcjAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAARKSURBVHhe7ZyxauNAFEX1G6rVpssPqHLjZps0KVS4SbHFdgZ/gyDVtoJtFhaMfmBBdQioD2qWEIybFMG4CMGYuxpLTiRFsiNbsubJ98ADe1Ac2XNmNDNvJAOECIGyEjFQViIGykrEQFmJGCgrEUMtWQ3DYDAqo21qy0pIGZSViIGyEjFQViIGykrEQFmJGCiraBaI/AmGbohVWrJlFd5iOPYRLddpiXwoq1jeMPN/YJAT8gm+cwnHf4pfL/DgjWCNfMx64itllcoiwNiaIFjsMvEZwXiIcfCcvpcNZRXJCnP/BuY4iPvPlLkPJ/7tDDMr8Dp2egIre1yDqLqqE8fSxGfsg7I2zhKha8PKjVVfEXlXMBwf87REsQpdWJaLsDioFQhlFUmJrOsHeAMLA+8h7k8/oKz1oKz7WN7Dtc3Nd89dxqvKSy7v68jDwLiCF72mJYp2hwHAS9xohsn5GZeZsXFV+XGcwg3Kupc1luEt7E3lmrDd+7jvVLP97zA3ZRcY+Y+5HjM/wUqkNE0bo2mUOe4EE6xsg7JvES7XWM98jEx13gbMBlcjKKsurB/hjy6SSje/Y3r3e0+FJzJbzi88lK6lJmuwg9aXrgqNahpgmvke/uwtPe54KKtGZHukjyhe2rNokhTINrT3MD+Nn49FfW7bUNYvk+2lkgpPhgT686mhpUOCJqGsmpFMlLaVfgN/LmQav1mNSMeuhpVm0ZqFsurEp8vpKXpWlaK1Mv+zKnY1nOIVIQ72rE2h4waQdEa/qewLXDvf0tdDuOFLeoymqJWJ7WTw2sH15nXzDe0MZVW9gIYbQIpLQPO7T0tCepJdU1UN61/hfXMNrX03dJNVyw0gxQpXFVy29qobFedYsvbaBGcmqx4bQPLskrJMYo2olLKdhnZmsp7nBpC+IFvWqtx5VXmZrGewAaQvyJa19HJTSP/lcuq6bAAhhyBc1pi6OXVdNoCQ2siXNaZeTj3pebvfAELq0gtZ6+fUm0oKNJH9IV9F/ZZtcwJZt2NPytFn+iFrJzn1Zvg45/OJQznmb79Ky7J2mVPnMOCUqN+ybdqVVWxOndRFuKxSc+rkEATLKjinTg5CsKzk3KCsRAyUlYiBshIxUNazYIEo+APXKd7bXwjNt0Sqc2wbytop2ZWRPUFZKWt3ZLN7BkznJ+7nb3HxDMFk8CHpwEMkIHdCWXuN2pd7mUpZ2DKZeyjFrkcU6QNl7TOrEK5V1Xsmt/gkstpwQ/3zfJS1z2zv3FVRuCGSspZDWbsi86SU3T0rhwFbKGtnZLcw7hizcoL1DmXtjK+sBpQ8VVtTKGvfKS5T5cKEPfmLuQRTY9Q5tw1l7RyVwfIw3m5KV2GP4QWRqL2+lJWIgbISMVBWIgbKSsRAWYkYKCsRA2UlYqCsRAyUlYhBS1kZjKpoG3aVRAyUlYiBshIxUFYiBspKxEBZiRgoKxEDZSVioKxECMB/pfVTkbDqLD0AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "144988ac",
   "metadata": {},
   "source": [
    "![desvio.PNG](attachment:desvio.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "99f6fcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-314-d7438a143774>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['fixed acidity'] = (train_df['fixed acidity'] - mean_fixed_acidity)/std_fixed_acidity\n",
      "<ipython-input-314-d7438a143774>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['residual sugar'] = (train_df['residual sugar'] - mean_residual_sugar)/std_residual_sugar\n",
      "<ipython-input-314-d7438a143774>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['free sulfur dioxide'] = (train_df['free sulfur dioxide'] - mean_free_sulfur_dioxide)/std_free_sulfur_dioxide\n",
      "<ipython-input-314-d7438a143774>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['total sulfur dioxide'] = (train_df['total sulfur dioxide'] - mean_total_sulfur_dioxide)/std_total_sulfur_dioxide\n",
      "<ipython-input-314-d7438a143774>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['alcohol'] = (train_df['alcohol'] - mean_alcohol)/std_alcohol\n"
     ]
    }
   ],
   "source": [
    "train_df['fixed acidity'] = (train_df['fixed acidity'] - mean_fixed_acidity)/std_fixed_acidity\n",
    "train_df['residual sugar'] = (train_df['residual sugar'] - mean_residual_sugar)/std_residual_sugar\n",
    "train_df['free sulfur dioxide'] = (train_df['free sulfur dioxide'] - mean_free_sulfur_dioxide)/std_free_sulfur_dioxide\n",
    "train_df['total sulfur dioxide'] = (train_df['total sulfur dioxide'] - mean_total_sulfur_dioxide)/std_total_sulfur_dioxide\n",
    "train_df['alcohol'] = (train_df['alcohol'] - mean_alcohol)/std_alcohol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85003b9",
   "metadata": {},
   "source": [
    "## Step 11\n",
    "\n",
    "Calculo de normalização, subtraindo os dado reais de treinamento pela média dos dados e subtraindo pelo desvio padrão. Porém desta vez, para os dados de teste.\n"
   ]
  },
  {
   "attachments": {
    "desvio.PNG": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKsAAABMCAYAAAASqUcjAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAARKSURBVHhe7ZyxauNAFEX1G6rVpssPqHLjZps0KVS4SbHFdgZ/gyDVtoJtFhaMfmBBdQioD2qWEIybFMG4CMGYuxpLTiRFsiNbsubJ98ADe1Ac2XNmNDNvJAOECIGyEjFQViIGykrEQFmJGCgrEUMtWQ3DYDAqo21qy0pIGZSViIGyEjFQViIGykrEQFmJGCiraBaI/AmGbohVWrJlFd5iOPYRLddpiXwoq1jeMPN/YJAT8gm+cwnHf4pfL/DgjWCNfMx64itllcoiwNiaIFjsMvEZwXiIcfCcvpcNZRXJCnP/BuY4iPvPlLkPJ/7tDDMr8Dp2egIre1yDqLqqE8fSxGfsg7I2zhKha8PKjVVfEXlXMBwf87REsQpdWJaLsDioFQhlFUmJrOsHeAMLA+8h7k8/oKz1oKz7WN7Dtc3Nd89dxqvKSy7v68jDwLiCF72mJYp2hwHAS9xohsn5GZeZsXFV+XGcwg3Kupc1luEt7E3lmrDd+7jvVLP97zA3ZRcY+Y+5HjM/wUqkNE0bo2mUOe4EE6xsg7JvES7XWM98jEx13gbMBlcjKKsurB/hjy6SSje/Y3r3e0+FJzJbzi88lK6lJmuwg9aXrgqNahpgmvke/uwtPe54KKtGZHukjyhe2rNokhTINrT3MD+Nn49FfW7bUNYvk+2lkgpPhgT686mhpUOCJqGsmpFMlLaVfgN/LmQav1mNSMeuhpVm0ZqFsurEp8vpKXpWlaK1Mv+zKnY1nOIVIQ72rE2h4waQdEa/qewLXDvf0tdDuOFLeoymqJWJ7WTw2sH15nXzDe0MZVW9gIYbQIpLQPO7T0tCepJdU1UN61/hfXMNrX03dJNVyw0gxQpXFVy29qobFedYsvbaBGcmqx4bQPLskrJMYo2olLKdhnZmsp7nBpC+IFvWqtx5VXmZrGewAaQvyJa19HJTSP/lcuq6bAAhhyBc1pi6OXVdNoCQ2siXNaZeTj3pebvfAELq0gtZ6+fUm0oKNJH9IV9F/ZZtcwJZt2NPytFn+iFrJzn1Zvg45/OJQznmb79Ky7J2mVPnMOCUqN+ybdqVVWxOndRFuKxSc+rkEATLKjinTg5CsKzk3KCsRAyUlYiBshIxUNazYIEo+APXKd7bXwjNt0Sqc2wbytop2ZWRPUFZKWt3ZLN7BkznJ+7nb3HxDMFk8CHpwEMkIHdCWXuN2pd7mUpZ2DKZeyjFrkcU6QNl7TOrEK5V1Xsmt/gkstpwQ/3zfJS1z2zv3FVRuCGSspZDWbsi86SU3T0rhwFbKGtnZLcw7hizcoL1DmXtjK+sBpQ8VVtTKGvfKS5T5cKEPfmLuQRTY9Q5tw1l7RyVwfIw3m5KV2GP4QWRqL2+lJWIgbISMVBWIgbKSsRAWYkYKCsRA2UlYqCsRAyUlYhBS1kZjKpoG3aVRAyUlYiBshIxUFYiBspKxEBZiRgoKxEDZSVioKxECMB/pfVTkbDqLD0AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "61b295b4",
   "metadata": {},
   "source": [
    "![desvio.PNG](attachment:desvio.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "603120b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-315-da0aee9b26e2>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['fixed acidity'] = (test_df['fixed acidity'] - mean_fixed_acidity)/std_fixed_acidity\n",
      "<ipython-input-315-da0aee9b26e2>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['residual sugar'] = (test_df['residual sugar'] - mean_residual_sugar)/std_residual_sugar\n",
      "<ipython-input-315-da0aee9b26e2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['free sulfur dioxide'] = (test_df['free sulfur dioxide'] - mean_free_sulfur_dioxide)/std_free_sulfur_dioxide\n",
      "<ipython-input-315-da0aee9b26e2>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['total sulfur dioxide'] = (test_df['total sulfur dioxide'] - mean_total_sulfur_dioxide)/std_total_sulfur_dioxide\n",
      "<ipython-input-315-da0aee9b26e2>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['alcohol'] = (test_df['alcohol'] - mean_alcohol)/std_alcohol\n"
     ]
    }
   ],
   "source": [
    "test_df['fixed acidity'] = (test_df['fixed acidity'] - mean_fixed_acidity)/std_fixed_acidity\n",
    "test_df['residual sugar'] = (test_df['residual sugar'] - mean_residual_sugar)/std_residual_sugar\n",
    "test_df['free sulfur dioxide'] = (test_df['free sulfur dioxide'] - mean_free_sulfur_dioxide)/std_free_sulfur_dioxide\n",
    "test_df['total sulfur dioxide'] = (test_df['total sulfur dioxide'] - mean_total_sulfur_dioxide)/std_total_sulfur_dioxide\n",
    "test_df['alcohol'] = (test_df['alcohol'] - mean_alcohol)/std_alcohol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae730067",
   "metadata": {},
   "source": [
    "## Step 12\n",
    "\n",
    "Verificação se possui erros e divergencias nos dados de treinamento. 'T' permite visualização transposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "0633d182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>-1.880044e-15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.977894</td>\n",
       "      <td>-0.714696</td>\n",
       "      <td>-0.255351</td>\n",
       "      <td>0.548502</td>\n",
       "      <td>4.165842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>5.259812e-01</td>\n",
       "      <td>0.178246</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>1.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>2.727443e-01</td>\n",
       "      <td>0.195051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual sugar</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>-1.965937e-15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.141345</td>\n",
       "      <td>-0.451272</td>\n",
       "      <td>-0.244250</td>\n",
       "      <td>0.031779</td>\n",
       "      <td>8.933720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>8.792338e-02</td>\n",
       "      <td>0.047526</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>4.826302e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.427277</td>\n",
       "      <td>-0.855173</td>\n",
       "      <td>-0.187719</td>\n",
       "      <td>0.575086</td>\n",
       "      <td>4.961212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>-7.912184e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.253827</td>\n",
       "      <td>-0.762980</td>\n",
       "      <td>-0.272132</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>7.090580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>9.967857e-01</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>0.996760</td>\n",
       "      <td>0.997900</td>\n",
       "      <td>1.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>3.310884e+00</td>\n",
       "      <td>0.154356</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>6.590461e-01</td>\n",
       "      <td>0.172629</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>1279.0</td>\n",
       "      <td>-9.558855e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.911727</td>\n",
       "      <td>-0.875768</td>\n",
       "      <td>-0.216521</td>\n",
       "      <td>0.631082</td>\n",
       "      <td>3.362247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count          mean       std       min       25%  \\\n",
       "fixed acidity         1279.0 -1.880044e-15  1.000000 -1.977894 -0.714696   \n",
       "volatile acidity      1279.0  5.259812e-01  0.178246  0.120000  0.390000   \n",
       "citric acid           1279.0  2.727443e-01  0.195051  0.000000  0.095000   \n",
       "residual sugar        1279.0 -1.965937e-15  1.000000 -1.141345 -0.451272   \n",
       "chlorides             1279.0  8.792338e-02  0.047526  0.012000  0.070000   \n",
       "free sulfur dioxide   1279.0  4.826302e-17  1.000000 -1.427277 -0.855173   \n",
       "total sulfur dioxide  1279.0 -7.912184e-17  1.000000 -1.253827 -0.762980   \n",
       "density               1279.0  9.967857e-01  0.001921  0.990070  0.995600   \n",
       "pH                    1279.0  3.310884e+00  0.154356  2.740000  3.210000   \n",
       "sulphates             1279.0  6.590461e-01  0.172629  0.330000  0.550000   \n",
       "alcohol               1279.0 -9.558855e-16  1.000000 -1.911727 -0.875768   \n",
       "\n",
       "                           50%       75%       max  \n",
       "fixed acidity        -0.255351  0.548502  4.165842  \n",
       "volatile acidity      0.520000  0.635000  1.580000  \n",
       "citric acid           0.260000  0.425000  1.000000  \n",
       "residual sugar       -0.244250  0.031779  8.933720  \n",
       "chlorides             0.080000  0.091000  0.611000  \n",
       "free sulfur dioxide  -0.187719  0.575086  4.961212  \n",
       "total sulfur dioxide -0.272132  0.494817  7.090580  \n",
       "density               0.996760  0.997900  1.003690  \n",
       "pH                    3.310000  3.400000  4.010000  \n",
       "sulphates             0.620000  0.730000  2.000000  \n",
       "alcohol              -0.216521  0.631082  3.362247  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2165d3",
   "metadata": {},
   "source": [
    "## Step 13\n",
    "\n",
    "Verificação se possui erros e divergencias nos dados de teste. 'T' permite visualização transposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "42bf6beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <td>320.0</td>\n",
       "      <td>-0.071972</td>\n",
       "      <td>0.998006</td>\n",
       "      <td>-2.150148</td>\n",
       "      <td>-0.714696</td>\n",
       "      <td>-0.312769</td>\n",
       "      <td>0.433666</td>\n",
       "      <td>4.338097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>320.0</td>\n",
       "      <td>0.535172</td>\n",
       "      <td>0.182373</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.393750</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>320.0</td>\n",
       "      <td>0.263906</td>\n",
       "      <td>0.193941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual sugar</th>\n",
       "      <td>320.0</td>\n",
       "      <td>-0.052216</td>\n",
       "      <td>0.856525</td>\n",
       "      <td>-1.141345</td>\n",
       "      <td>-0.451272</td>\n",
       "      <td>-0.244250</td>\n",
       "      <td>0.031779</td>\n",
       "      <td>7.484567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>320.0</td>\n",
       "      <td>0.085641</td>\n",
       "      <td>0.045203</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.070750</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <td>320.0</td>\n",
       "      <td>-0.044693</td>\n",
       "      <td>0.987592</td>\n",
       "      <td>-1.236576</td>\n",
       "      <td>-0.759823</td>\n",
       "      <td>-0.283070</td>\n",
       "      <td>0.479735</td>\n",
       "      <td>5.342615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>320.0</td>\n",
       "      <td>-0.061748</td>\n",
       "      <td>1.045125</td>\n",
       "      <td>-1.253827</td>\n",
       "      <td>-0.801327</td>\n",
       "      <td>-0.364166</td>\n",
       "      <td>0.402783</td>\n",
       "      <td>7.428038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>320.0</td>\n",
       "      <td>0.996591</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>0.995638</td>\n",
       "      <td>0.996605</td>\n",
       "      <td>0.997600</td>\n",
       "      <td>1.003150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>320.0</td>\n",
       "      <td>3.312031</td>\n",
       "      <td>0.154745</td>\n",
       "      <td>2.890000</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>320.0</td>\n",
       "      <td>0.654563</td>\n",
       "      <td>0.156611</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>1.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>320.0</td>\n",
       "      <td>-0.032580</td>\n",
       "      <td>1.019153</td>\n",
       "      <td>-1.629193</td>\n",
       "      <td>-0.875768</td>\n",
       "      <td>-0.310699</td>\n",
       "      <td>0.631082</td>\n",
       "      <td>4.209850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count      mean       std       min       25%       50%  \\\n",
       "fixed acidity         320.0 -0.071972  0.998006 -2.150148 -0.714696 -0.312769   \n",
       "volatile acidity      320.0  0.535172  0.182373  0.120000  0.393750  0.540000   \n",
       "citric acid           320.0  0.263906  0.193941  0.000000  0.087500  0.240000   \n",
       "residual sugar        320.0 -0.052216  0.856525 -1.141345 -0.451272 -0.244250   \n",
       "chlorides             320.0  0.085641  0.045203  0.012000  0.070750  0.078000   \n",
       "free sulfur dioxide   320.0 -0.044693  0.987592 -1.236576 -0.759823 -0.283070   \n",
       "total sulfur dioxide  320.0 -0.061748  1.045125 -1.253827 -0.801327 -0.364166   \n",
       "density               320.0  0.996591  0.001740  0.990070  0.995638  0.996605   \n",
       "pH                    320.0  3.312031  0.154745  2.890000  3.210000  3.320000   \n",
       "sulphates             320.0  0.654563  0.156611  0.390000  0.550000  0.620000   \n",
       "alcohol               320.0 -0.032580  1.019153 -1.629193 -0.875768 -0.310699   \n",
       "\n",
       "                           75%       max  \n",
       "fixed acidity         0.433666  4.338097  \n",
       "volatile acidity      0.640000  1.185000  \n",
       "citric acid           0.420000  0.740000  \n",
       "residual sugar        0.031779  7.484567  \n",
       "chlorides             0.088000  0.467000  \n",
       "free sulfur dioxide   0.479735  5.342615  \n",
       "total sulfur dioxide  0.402783  7.428038  \n",
       "density               0.997600  1.003150  \n",
       "pH                    3.410000  3.900000  \n",
       "sulphates             0.730000  1.310000  \n",
       "alcohol               0.631082  4.209850  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c33194",
   "metadata": {},
   "source": [
    "## Step 14\n",
    "\n",
    "Atribuição dos dados de entrada. X_train e X_test recebe o tensor numpy de train_df e test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "3f08f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de Entrada\n",
    "X_train = np.array(train_df)\n",
    "X_test = np.array(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420b2657",
   "metadata": {},
   "source": [
    "## Step 15\n",
    "\n",
    "Importação de bibliotecas que serão utilizadas para treinar a RNA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c57d2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TREINAR A REDE, importando bibliotecas\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c7722d",
   "metadata": {},
   "source": [
    "## Step 16\n",
    "\n",
    "Apenas para verificação, impresso a dimensão da matriz X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "0d10f5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f07d3",
   "metadata": {},
   "source": [
    "## Step 17\n",
    "\n",
    "x_dim é atribuido pela dimensão de shape disposta no 2°eixo (11 elementos), correspondente as características dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d852517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76800cd3",
   "metadata": {},
   "source": [
    "## Step 18\n",
    "\n",
    "Seleção do objeto de inicialização da Rede Neural e criado RNA com 3 camadas constituída de 64 neurônios da 1° camada (função 'relu'), 32 neurônios da 2° camada (função 'relu') e 1 neurônio na camada de saída (função 'sigmoid')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "c1b66c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,881\n",
      "Trainable params: 2,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Selecionando o inicializador, objeto de inicialização\n",
    "inicial = initializers.GlorotNormal()\n",
    "\n",
    "\n",
    "#Criando RNA\n",
    "rna = Sequential()\n",
    "rna.add(layers.Dense(64, activation = 'relu', kernel_initializer=inicial, input_dim=x_dim))\n",
    "rna.add(layers.Dense(32, activation = 'relu', kernel_initializer=inicial))\n",
    "rna.add(layers.Dense(1, activation = 'sigmoid', kernel_initializer=inicial))\n",
    "\n",
    "\n",
    "rna.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a33f6",
   "metadata": {},
   "source": [
    "## Step 19\n",
    "\n",
    "Compilação da RNA utilizando otimizador 'Adam', função de custo 'binary_crossentropy' e 'accuracy' (exatidão) como métrica. Para esta RNA foi realizado o treinamento em 1000 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d1a46b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.6302 - val_loss: 0.5994 - val_accuracy: 0.7219\n",
      "Epoch 2/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7170 - val_loss: 0.5654 - val_accuracy: 0.7375\n",
      "Epoch 3/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7248 - val_loss: 0.5545 - val_accuracy: 0.7375\n",
      "Epoch 4/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7240 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
      "Epoch 5/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7357 - val_loss: 0.5471 - val_accuracy: 0.7375\n",
      "Epoch 6/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7295 - val_loss: 0.5404 - val_accuracy: 0.7375\n",
      "Epoch 7/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7342 - val_loss: 0.5372 - val_accuracy: 0.7469\n",
      "Epoch 8/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7389 - val_loss: 0.5405 - val_accuracy: 0.7437\n",
      "Epoch 9/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7435 - val_loss: 0.5329 - val_accuracy: 0.7500\n",
      "Epoch 10/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7443 - val_loss: 0.5294 - val_accuracy: 0.7594\n",
      "Epoch 11/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7420 - val_loss: 0.5348 - val_accuracy: 0.7406\n",
      "Epoch 12/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7475 - val_loss: 0.5436 - val_accuracy: 0.7406\n",
      "Epoch 13/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7506 - val_loss: 0.5306 - val_accuracy: 0.7625\n",
      "Epoch 14/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7522 - val_loss: 0.5259 - val_accuracy: 0.7563\n",
      "Epoch 15/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7514 - val_loss: 0.5236 - val_accuracy: 0.7531\n",
      "Epoch 16/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7514 - val_loss: 0.5175 - val_accuracy: 0.7594\n",
      "Epoch 17/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7553 - val_loss: 0.5310 - val_accuracy: 0.7437\n",
      "Epoch 18/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7615 - val_loss: 0.5209 - val_accuracy: 0.7563\n",
      "Epoch 19/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7631 - val_loss: 0.5195 - val_accuracy: 0.7531\n",
      "Epoch 20/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7694 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
      "Epoch 21/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7592 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
      "Epoch 22/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7561 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
      "Epoch 23/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7662 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 24/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7662 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 25/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7686 - val_loss: 0.5116 - val_accuracy: 0.7625\n",
      "Epoch 26/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7678 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
      "Epoch 27/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7686 - val_loss: 0.5112 - val_accuracy: 0.7625\n",
      "Epoch 28/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7709 - val_loss: 0.5173 - val_accuracy: 0.7625\n",
      "Epoch 29/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7709 - val_loss: 0.5156 - val_accuracy: 0.7563\n",
      "Epoch 30/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7709 - val_loss: 0.5294 - val_accuracy: 0.7625\n",
      "Epoch 31/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7678 - val_loss: 0.5101 - val_accuracy: 0.7563\n",
      "Epoch 32/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7639 - val_loss: 0.5238 - val_accuracy: 0.7688\n",
      "Epoch 33/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7819 - val_loss: 0.5085 - val_accuracy: 0.7688\n",
      "Epoch 34/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7694 - val_loss: 0.5182 - val_accuracy: 0.7594\n",
      "Epoch 35/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7780 - val_loss: 0.5142 - val_accuracy: 0.7594\n",
      "Epoch 36/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7717 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 37/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7717 - val_loss: 0.5063 - val_accuracy: 0.7625\n",
      "Epoch 38/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7780 - val_loss: 0.5065 - val_accuracy: 0.7688\n",
      "Epoch 39/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7740 - val_loss: 0.5022 - val_accuracy: 0.7688\n",
      "Epoch 40/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7694 - val_loss: 0.5104 - val_accuracy: 0.7688\n",
      "Epoch 41/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7819 - val_loss: 0.5079 - val_accuracy: 0.7688\n",
      "Epoch 42/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7850 - val_loss: 0.5023 - val_accuracy: 0.7625\n",
      "Epoch 43/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7756 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 44/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7764 - val_loss: 0.5015 - val_accuracy: 0.7781\n",
      "Epoch 45/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7756 - val_loss: 0.5121 - val_accuracy: 0.7750\n",
      "Epoch 46/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7772 - val_loss: 0.5020 - val_accuracy: 0.7625\n",
      "Epoch 47/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.5247 - val_accuracy: 0.7563\n",
      "Epoch 48/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7803 - val_loss: 0.5067 - val_accuracy: 0.7812\n",
      "Epoch 49/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7625\n",
      "Epoch 50/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7795 - val_loss: 0.5126 - val_accuracy: 0.7688\n",
      "Epoch 51/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7873 - val_loss: 0.5056 - val_accuracy: 0.7781\n",
      "Epoch 52/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7563\n",
      "Epoch 53/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7780 - val_loss: 0.5041 - val_accuracy: 0.7781\n",
      "Epoch 54/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7780 - val_loss: 0.5071 - val_accuracy: 0.7563\n",
      "Epoch 55/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7826 - val_loss: 0.5021 - val_accuracy: 0.7719\n",
      "Epoch 56/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7866 - val_loss: 0.5189 - val_accuracy: 0.7563\n",
      "Epoch 57/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7920 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 58/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7912 - val_loss: 0.5218 - val_accuracy: 0.7594\n",
      "Epoch 59/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7873 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 60/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7889 - val_loss: 0.5238 - val_accuracy: 0.7437\n",
      "Epoch 61/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7850 - val_loss: 0.5128 - val_accuracy: 0.7688\n",
      "Epoch 62/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7772 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 63/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7905 - val_loss: 0.5236 - val_accuracy: 0.7563\n",
      "Epoch 64/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7912 - val_loss: 0.5060 - val_accuracy: 0.7844\n",
      "Epoch 65/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7928 - val_loss: 0.5054 - val_accuracy: 0.7812\n",
      "Epoch 66/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7881 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 67/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7881 - val_loss: 0.5127 - val_accuracy: 0.7781\n",
      "Epoch 68/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7866 - val_loss: 0.5031 - val_accuracy: 0.7750\n",
      "Epoch 69/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7920 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
      "Epoch 70/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7967 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 71/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7850 - val_loss: 0.5042 - val_accuracy: 0.7688\n",
      "Epoch 72/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7920 - val_loss: 0.5055 - val_accuracy: 0.7719\n",
      "Epoch 73/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7967 - val_loss: 0.5068 - val_accuracy: 0.7719\n",
      "Epoch 74/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8006 - val_loss: 0.5383 - val_accuracy: 0.7281\n",
      "Epoch 75/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7905 - val_loss: 0.5002 - val_accuracy: 0.7688\n",
      "Epoch 76/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7998 - val_loss: 0.5145 - val_accuracy: 0.7563\n",
      "Epoch 77/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7842 - val_loss: 0.5027 - val_accuracy: 0.7781\n",
      "Epoch 78/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7944 - val_loss: 0.5130 - val_accuracy: 0.7781\n",
      "Epoch 79/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7967 - val_loss: 0.5254 - val_accuracy: 0.7531\n",
      "Epoch 80/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7975 - val_loss: 0.5027 - val_accuracy: 0.7844\n",
      "Epoch 81/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8030 - val_loss: 0.5022 - val_accuracy: 0.7750\n",
      "Epoch 82/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7959 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
      "Epoch 83/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7975 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
      "Epoch 84/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7897 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
      "Epoch 85/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8014 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 86/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7944 - val_loss: 0.5272 - val_accuracy: 0.7563\n",
      "Epoch 87/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7928 - val_loss: 0.5020 - val_accuracy: 0.7688\n",
      "Epoch 88/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7975 - val_loss: 0.5103 - val_accuracy: 0.7688\n",
      "Epoch 89/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7959 - val_loss: 0.5166 - val_accuracy: 0.7563\n",
      "Epoch 90/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8014 - val_loss: 0.5172 - val_accuracy: 0.7719\n",
      "Epoch 91/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8014 - val_loss: 0.5088 - val_accuracy: 0.7750\n",
      "Epoch 92/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8045 - val_loss: 0.5517 - val_accuracy: 0.7250\n",
      "Epoch 93/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7998 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
      "Epoch 94/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7991 - val_loss: 0.5118 - val_accuracy: 0.7625\n",
      "Epoch 95/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.7975 - val_loss: 0.5200 - val_accuracy: 0.7719\n",
      "Epoch 96/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8045 - val_loss: 0.5081 - val_accuracy: 0.7688\n",
      "Epoch 97/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7920 - val_loss: 0.5387 - val_accuracy: 0.7344\n",
      "Epoch 98/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8108 - val_loss: 0.5157 - val_accuracy: 0.7688\n",
      "Epoch 99/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8022 - val_loss: 0.5271 - val_accuracy: 0.7563\n",
      "Epoch 100/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8030 - val_loss: 0.5097 - val_accuracy: 0.7781\n",
      "Epoch 101/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8069 - val_loss: 0.5305 - val_accuracy: 0.7437\n",
      "Epoch 102/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.7967 - val_loss: 0.5334 - val_accuracy: 0.7406\n",
      "Epoch 103/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8030 - val_loss: 0.5104 - val_accuracy: 0.7750\n",
      "Epoch 104/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8053 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
      "Epoch 105/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8045 - val_loss: 0.5084 - val_accuracy: 0.7844\n",
      "Epoch 106/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.7967 - val_loss: 0.5291 - val_accuracy: 0.7625\n",
      "Epoch 107/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8061 - val_loss: 0.5072 - val_accuracy: 0.7688\n",
      "Epoch 108/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8045 - val_loss: 0.5173 - val_accuracy: 0.7781\n",
      "Epoch 109/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.7998 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
      "Epoch 110/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8030 - val_loss: 0.5116 - val_accuracy: 0.7750\n",
      "Epoch 111/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8084 - val_loss: 0.5393 - val_accuracy: 0.7594\n",
      "Epoch 112/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8092 - val_loss: 0.5142 - val_accuracy: 0.7750\n",
      "Epoch 113/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.7991 - val_loss: 0.5280 - val_accuracy: 0.7688\n",
      "Epoch 114/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.7998 - val_loss: 0.5143 - val_accuracy: 0.7781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8045 - val_loss: 0.5420 - val_accuracy: 0.7469\n",
      "Epoch 116/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.7959 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
      "Epoch 117/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8069 - val_loss: 0.5102 - val_accuracy: 0.7844\n",
      "Epoch 118/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8061 - val_loss: 0.5105 - val_accuracy: 0.7719\n",
      "Epoch 119/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8084 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
      "Epoch 120/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8131 - val_loss: 0.5234 - val_accuracy: 0.7750\n",
      "Epoch 121/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8100 - val_loss: 0.5233 - val_accuracy: 0.7688\n",
      "Epoch 122/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8069 - val_loss: 0.5312 - val_accuracy: 0.7688\n",
      "Epoch 123/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.81 - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8131 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
      "Epoch 124/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8147 - val_loss: 0.5274 - val_accuracy: 0.7594\n",
      "Epoch 125/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8170 - val_loss: 0.5152 - val_accuracy: 0.7781\n",
      "Epoch 126/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8061 - val_loss: 0.5240 - val_accuracy: 0.7719\n",
      "Epoch 127/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8084 - val_loss: 0.5146 - val_accuracy: 0.7750\n",
      "Epoch 128/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8139 - val_loss: 0.5190 - val_accuracy: 0.7719\n",
      "Epoch 129/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8210 - val_loss: 0.5292 - val_accuracy: 0.7375\n",
      "Epoch 130/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8131 - val_loss: 0.5296 - val_accuracy: 0.7688\n",
      "Epoch 131/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8217 - val_loss: 0.5102 - val_accuracy: 0.7688\n",
      "Epoch 132/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8061 - val_loss: 0.5356 - val_accuracy: 0.7375\n",
      "Epoch 133/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8061 - val_loss: 0.5337 - val_accuracy: 0.7563\n",
      "Epoch 134/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8139 - val_loss: 0.5121 - val_accuracy: 0.7812\n",
      "Epoch 135/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8170 - val_loss: 0.5173 - val_accuracy: 0.7594\n",
      "Epoch 136/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8061 - val_loss: 0.5216 - val_accuracy: 0.7719\n",
      "Epoch 137/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8131 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
      "Epoch 138/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8155 - val_loss: 0.5197 - val_accuracy: 0.7812\n",
      "Epoch 139/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8124 - val_loss: 0.5133 - val_accuracy: 0.7875\n",
      "Epoch 140/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8131 - val_loss: 0.5296 - val_accuracy: 0.7625\n",
      "Epoch 141/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8170 - val_loss: 0.5256 - val_accuracy: 0.7688\n",
      "Epoch 142/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7688\n",
      "Epoch 143/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8139 - val_loss: 0.5228 - val_accuracy: 0.7781\n",
      "Epoch 144/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8233 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
      "Epoch 145/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8131 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 146/1000\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3770 - accuracy: 0.8147 - val_loss: 0.5387 - val_accuracy: 0.7437\n",
      "Epoch 147/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8194 - val_loss: 0.5279 - val_accuracy: 0.7625\n",
      "Epoch 148/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8170 - val_loss: 0.5197 - val_accuracy: 0.7750\n",
      "Epoch 149/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8194 - val_loss: 0.5292 - val_accuracy: 0.7750\n",
      "Epoch 150/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8264 - val_loss: 0.5198 - val_accuracy: 0.7844\n",
      "Epoch 151/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8178 - val_loss: 0.5217 - val_accuracy: 0.7719\n",
      "Epoch 152/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8186 - val_loss: 0.5299 - val_accuracy: 0.7594\n",
      "Epoch 153/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8225 - val_loss: 0.5190 - val_accuracy: 0.7812\n",
      "Epoch 154/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8264 - val_loss: 0.5282 - val_accuracy: 0.7531\n",
      "Epoch 155/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8225 - val_loss: 0.5265 - val_accuracy: 0.7719\n",
      "Epoch 156/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8233 - val_loss: 0.5300 - val_accuracy: 0.7812\n",
      "Epoch 157/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8303 - val_loss: 0.5228 - val_accuracy: 0.7906\n",
      "Epoch 158/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8233 - val_loss: 0.5229 - val_accuracy: 0.7781\n",
      "Epoch 159/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8280 - val_loss: 0.5194 - val_accuracy: 0.7844\n",
      "Epoch 160/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8170 - val_loss: 0.5516 - val_accuracy: 0.7406\n",
      "Epoch 161/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8280 - val_loss: 0.5287 - val_accuracy: 0.7719\n",
      "Epoch 162/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8342 - val_loss: 0.5301 - val_accuracy: 0.7719\n",
      "Epoch 163/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8288 - val_loss: 0.5382 - val_accuracy: 0.7656\n",
      "Epoch 164/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8186 - val_loss: 0.5275 - val_accuracy: 0.7656\n",
      "Epoch 165/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8256 - val_loss: 0.5383 - val_accuracy: 0.7719\n",
      "Epoch 166/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8327 - val_loss: 0.5371 - val_accuracy: 0.7781\n",
      "Epoch 167/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8264 - val_loss: 0.5181 - val_accuracy: 0.7844\n",
      "Epoch 168/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8296 - val_loss: 0.5293 - val_accuracy: 0.7625\n",
      "Epoch 169/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8288 - val_loss: 0.5786 - val_accuracy: 0.7281\n",
      "Epoch 170/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8335 - val_loss: 0.5365 - val_accuracy: 0.7719\n",
      "Epoch 171/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8241 - val_loss: 0.5549 - val_accuracy: 0.7500\n",
      "Epoch 172/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8319 - val_loss: 0.5455 - val_accuracy: 0.7531\n",
      "Epoch 173/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8296 - val_loss: 0.5241 - val_accuracy: 0.7625\n",
      "Epoch 174/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8249 - val_loss: 0.5301 - val_accuracy: 0.7750\n",
      "Epoch 175/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8342 - val_loss: 0.5421 - val_accuracy: 0.7719\n",
      "Epoch 176/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8327 - val_loss: 0.5231 - val_accuracy: 0.7750\n",
      "Epoch 177/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8241 - val_loss: 0.5402 - val_accuracy: 0.7688\n",
      "Epoch 178/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8249 - val_loss: 0.5263 - val_accuracy: 0.7688\n",
      "Epoch 179/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8382 - val_loss: 0.5211 - val_accuracy: 0.7844\n",
      "Epoch 180/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8327 - val_loss: 0.5391 - val_accuracy: 0.7594\n",
      "Epoch 181/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8296 - val_loss: 0.5237 - val_accuracy: 0.7594\n",
      "Epoch 182/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8296 - val_loss: 0.5348 - val_accuracy: 0.7719\n",
      "Epoch 183/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8327 - val_loss: 0.5541 - val_accuracy: 0.7656\n",
      "Epoch 184/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8374 - val_loss: 0.5554 - val_accuracy: 0.7656\n",
      "Epoch 185/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8319 - val_loss: 0.5256 - val_accuracy: 0.7812\n",
      "Epoch 186/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8342 - val_loss: 0.5377 - val_accuracy: 0.7812\n",
      "Epoch 187/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8413 - val_loss: 0.5296 - val_accuracy: 0.7844\n",
      "Epoch 188/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8358 - val_loss: 0.5238 - val_accuracy: 0.7688\n",
      "Epoch 189/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8444 - val_loss: 0.5419 - val_accuracy: 0.7750\n",
      "Epoch 190/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8374 - val_loss: 0.5325 - val_accuracy: 0.7563\n",
      "Epoch 191/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8421 - val_loss: 0.5484 - val_accuracy: 0.7594\n",
      "Epoch 192/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8358 - val_loss: 0.5413 - val_accuracy: 0.7750\n",
      "Epoch 193/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8444 - val_loss: 0.5422 - val_accuracy: 0.7688\n",
      "Epoch 194/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8397 - val_loss: 0.5386 - val_accuracy: 0.7688\n",
      "Epoch 195/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 0.96 - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8475 - val_loss: 0.5593 - val_accuracy: 0.7625\n",
      "Epoch 196/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8428 - val_loss: 0.5359 - val_accuracy: 0.7719\n",
      "Epoch 197/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8421 - val_loss: 0.5421 - val_accuracy: 0.7875\n",
      "Epoch 198/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8413 - val_loss: 0.5699 - val_accuracy: 0.7625\n",
      "Epoch 199/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8397 - val_loss: 0.5671 - val_accuracy: 0.7469\n",
      "Epoch 200/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8483 - val_loss: 0.5412 - val_accuracy: 0.7719\n",
      "Epoch 201/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8366 - val_loss: 0.5448 - val_accuracy: 0.7688\n",
      "Epoch 202/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8444 - val_loss: 0.5563 - val_accuracy: 0.7812\n",
      "Epoch 203/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8491 - val_loss: 0.5303 - val_accuracy: 0.7719\n",
      "Epoch 204/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8483 - val_loss: 0.5224 - val_accuracy: 0.7844\n",
      "Epoch 205/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8405 - val_loss: 0.5499 - val_accuracy: 0.7781\n",
      "Epoch 206/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8460 - val_loss: 0.5235 - val_accuracy: 0.7812\n",
      "Epoch 207/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8468 - val_loss: 0.5255 - val_accuracy: 0.7875\n",
      "Epoch 208/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8530 - val_loss: 0.5462 - val_accuracy: 0.7781\n",
      "Epoch 209/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8468 - val_loss: 0.5401 - val_accuracy: 0.7781\n",
      "Epoch 210/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8483 - val_loss: 0.5255 - val_accuracy: 0.7875\n",
      "Epoch 211/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8499 - val_loss: 0.5345 - val_accuracy: 0.7750\n",
      "Epoch 212/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8358 - val_loss: 0.5504 - val_accuracy: 0.7656\n",
      "Epoch 213/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8413 - val_loss: 0.5305 - val_accuracy: 0.7906\n",
      "Epoch 214/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8507 - val_loss: 0.5291 - val_accuracy: 0.7969\n",
      "Epoch 215/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8530 - val_loss: 0.5813 - val_accuracy: 0.7594\n",
      "Epoch 216/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8428 - val_loss: 0.5344 - val_accuracy: 0.7812\n",
      "Epoch 217/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8593 - val_loss: 0.5403 - val_accuracy: 0.7844\n",
      "Epoch 218/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8561 - val_loss: 0.5562 - val_accuracy: 0.7625\n",
      "Epoch 219/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8514 - val_loss: 0.5411 - val_accuracy: 0.7625\n",
      "Epoch 220/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8530 - val_loss: 0.5474 - val_accuracy: 0.7688\n",
      "Epoch 221/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8577 - val_loss: 0.5351 - val_accuracy: 0.7750\n",
      "Epoch 222/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8546 - val_loss: 0.5280 - val_accuracy: 0.8031\n",
      "Epoch 223/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8452 - val_loss: 0.5443 - val_accuracy: 0.7844\n",
      "Epoch 224/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8475 - val_loss: 0.5263 - val_accuracy: 0.7937\n",
      "Epoch 225/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8585 - val_loss: 0.5505 - val_accuracy: 0.7812\n",
      "Epoch 226/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8475 - val_loss: 0.5473 - val_accuracy: 0.7781\n",
      "Epoch 227/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8600 - val_loss: 0.5460 - val_accuracy: 0.7781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8514 - val_loss: 0.5618 - val_accuracy: 0.7688\n",
      "Epoch 229/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8514 - val_loss: 0.5382 - val_accuracy: 0.7875\n",
      "Epoch 230/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8546 - val_loss: 0.5402 - val_accuracy: 0.7875\n",
      "Epoch 231/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8522 - val_loss: 0.5458 - val_accuracy: 0.7719\n",
      "Epoch 232/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8624 - val_loss: 0.5332 - val_accuracy: 0.7625\n",
      "Epoch 233/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8546 - val_loss: 0.5294 - val_accuracy: 0.7844\n",
      "Epoch 234/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8554 - val_loss: 0.5398 - val_accuracy: 0.7812\n",
      "Epoch 235/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8616 - val_loss: 0.5552 - val_accuracy: 0.7750\n",
      "Epoch 236/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8538 - val_loss: 0.5450 - val_accuracy: 0.7719\n",
      "Epoch 237/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8585 - val_loss: 0.5531 - val_accuracy: 0.7656\n",
      "Epoch 238/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8585 - val_loss: 0.5427 - val_accuracy: 0.7875\n",
      "Epoch 239/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.8600 - val_loss: 0.5472 - val_accuracy: 0.7750\n",
      "Epoch 240/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8671 - val_loss: 0.5333 - val_accuracy: 0.7906\n",
      "Epoch 241/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3232 - accuracy: 0.8569 - val_loss: 0.5751 - val_accuracy: 0.7594\n",
      "Epoch 242/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8514 - val_loss: 0.5364 - val_accuracy: 0.7812\n",
      "Epoch 243/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8632 - val_loss: 0.5479 - val_accuracy: 0.7500\n",
      "Epoch 244/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8616 - val_loss: 0.5832 - val_accuracy: 0.7656\n",
      "Epoch 245/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8569 - val_loss: 0.5350 - val_accuracy: 0.7750\n",
      "Epoch 246/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8460 - val_loss: 0.5375 - val_accuracy: 0.7844\n",
      "Epoch 247/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3313 - accuracy: 0.8499 - val_loss: 0.5475 - val_accuracy: 0.7781\n",
      "Epoch 248/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3130 - accuracy: 0.8686 - val_loss: 0.5565 - val_accuracy: 0.7656\n",
      "Epoch 249/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3101 - accuracy: 0.8640 - val_loss: 0.5416 - val_accuracy: 0.7750\n",
      "Epoch 250/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8647 - val_loss: 0.5453 - val_accuracy: 0.7781\n",
      "Epoch 251/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8663 - val_loss: 0.5555 - val_accuracy: 0.7781\n",
      "Epoch 252/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8671 - val_loss: 0.5364 - val_accuracy: 0.7781\n",
      "Epoch 253/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8569 - val_loss: 0.5603 - val_accuracy: 0.7812\n",
      "Epoch 254/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8640 - val_loss: 0.5661 - val_accuracy: 0.7500\n",
      "Epoch 255/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8726 - val_loss: 0.5437 - val_accuracy: 0.7844\n",
      "Epoch 256/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8647 - val_loss: 0.5471 - val_accuracy: 0.7812\n",
      "Epoch 257/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.8538 - val_loss: 0.5398 - val_accuracy: 0.7844\n",
      "Epoch 258/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.8671 - val_loss: 0.5471 - val_accuracy: 0.7656\n",
      "Epoch 259/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8686 - val_loss: 0.5441 - val_accuracy: 0.7688\n",
      "Epoch 260/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8726 - val_loss: 0.5752 - val_accuracy: 0.7594\n",
      "Epoch 261/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.8632 - val_loss: 0.5583 - val_accuracy: 0.7781\n",
      "Epoch 262/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.8686 - val_loss: 0.5471 - val_accuracy: 0.7719\n",
      "Epoch 263/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8608 - val_loss: 0.5458 - val_accuracy: 0.7812\n",
      "Epoch 264/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8679 - val_loss: 0.5553 - val_accuracy: 0.7656\n",
      "Epoch 265/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8671 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
      "Epoch 266/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8640 - val_loss: 0.5587 - val_accuracy: 0.7688\n",
      "Epoch 267/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8679 - val_loss: 0.5466 - val_accuracy: 0.7750\n",
      "Epoch 268/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8710 - val_loss: 0.5442 - val_accuracy: 0.7937\n",
      "Epoch 269/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8632 - val_loss: 0.5512 - val_accuracy: 0.7750\n",
      "Epoch 270/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8812 - val_loss: 0.5543 - val_accuracy: 0.7719\n",
      "Epoch 271/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3047 - accuracy: 0.8624 - val_loss: 0.5612 - val_accuracy: 0.7812\n",
      "Epoch 272/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8600 - val_loss: 0.5559 - val_accuracy: 0.8031\n",
      "Epoch 273/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.8671 - val_loss: 0.5794 - val_accuracy: 0.7656\n",
      "Epoch 274/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8616 - val_loss: 0.5649 - val_accuracy: 0.7781\n",
      "Epoch 275/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8608 - val_loss: 0.5393 - val_accuracy: 0.7906\n",
      "Epoch 276/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8765 - val_loss: 0.5609 - val_accuracy: 0.7875\n",
      "Epoch 277/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3023 - accuracy: 0.8647 - val_loss: 0.5775 - val_accuracy: 0.7750\n",
      "Epoch 278/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8655 - val_loss: 0.5728 - val_accuracy: 0.7500\n",
      "Epoch 279/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.8655 - val_loss: 0.5823 - val_accuracy: 0.7500\n",
      "Epoch 280/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.8702 - val_loss: 0.5656 - val_accuracy: 0.7781\n",
      "Epoch 281/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8686 - val_loss: 0.5996 - val_accuracy: 0.7375\n",
      "Epoch 282/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8694 - val_loss: 0.5682 - val_accuracy: 0.7531\n",
      "Epoch 283/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.8741 - val_loss: 0.5618 - val_accuracy: 0.7875\n",
      "Epoch 284/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.8772 - val_loss: 0.5618 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8733 - val_loss: 0.5765 - val_accuracy: 0.7625\n",
      "Epoch 286/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2948 - accuracy: 0.8726 - val_loss: 0.5658 - val_accuracy: 0.7719\n",
      "Epoch 287/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.8788 - val_loss: 0.5557 - val_accuracy: 0.7812\n",
      "Epoch 288/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8726 - val_loss: 0.5703 - val_accuracy: 0.7719\n",
      "Epoch 289/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2989 - accuracy: 0.8733 - val_loss: 0.5921 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8733 - val_loss: 0.5718 - val_accuracy: 0.7781\n",
      "Epoch 291/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.8702 - val_loss: 0.5777 - val_accuracy: 0.7781\n",
      "Epoch 292/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.8702 - val_loss: 0.5693 - val_accuracy: 0.7719\n",
      "Epoch 293/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2924 - accuracy: 0.8741 - val_loss: 0.5729 - val_accuracy: 0.7937\n",
      "Epoch 294/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2885 - accuracy: 0.8804 - val_loss: 0.5799 - val_accuracy: 0.7656\n",
      "Epoch 295/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.8741 - val_loss: 0.5729 - val_accuracy: 0.7688\n",
      "Epoch 296/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.8827 - val_loss: 0.5926 - val_accuracy: 0.7875\n",
      "Epoch 297/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.8765 - val_loss: 0.5740 - val_accuracy: 0.7531\n",
      "Epoch 298/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.8819 - val_loss: 0.5718 - val_accuracy: 0.7625\n",
      "Epoch 299/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2893 - accuracy: 0.8866 - val_loss: 0.5711 - val_accuracy: 0.7750\n",
      "Epoch 300/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.8686 - val_loss: 0.5890 - val_accuracy: 0.7406\n",
      "Epoch 301/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.8772 - val_loss: 0.5727 - val_accuracy: 0.7688\n",
      "Epoch 302/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.8765 - val_loss: 0.6020 - val_accuracy: 0.7531\n",
      "Epoch 303/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2842 - accuracy: 0.8812 - val_loss: 0.5763 - val_accuracy: 0.7781\n",
      "Epoch 304/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.8749 - val_loss: 0.5833 - val_accuracy: 0.7719\n",
      "Epoch 305/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2873 - accuracy: 0.8780 - val_loss: 0.5914 - val_accuracy: 0.7625\n",
      "Epoch 306/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.8827 - val_loss: 0.6050 - val_accuracy: 0.7469\n",
      "Epoch 307/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.8726 - val_loss: 0.5989 - val_accuracy: 0.7594\n",
      "Epoch 308/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2816 - accuracy: 0.8788 - val_loss: 0.5941 - val_accuracy: 0.7594\n",
      "Epoch 309/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2845 - accuracy: 0.8796 - val_loss: 0.5875 - val_accuracy: 0.7750\n",
      "Epoch 310/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.8890 - val_loss: 0.5818 - val_accuracy: 0.7688\n",
      "Epoch 311/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8874 - val_loss: 0.5933 - val_accuracy: 0.7594\n",
      "Epoch 312/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8749 - val_loss: 0.5742 - val_accuracy: 0.7625\n",
      "Epoch 313/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.2820 - accuracy: 0.8843 - val_loss: 0.5761 - val_accuracy: 0.7781\n",
      "Epoch 314/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.8827 - val_loss: 0.6226 - val_accuracy: 0.7594\n",
      "Epoch 315/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2849 - accuracy: 0.8819 - val_loss: 0.5740 - val_accuracy: 0.7781\n",
      "Epoch 316/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8858 - val_loss: 0.6033 - val_accuracy: 0.7688\n",
      "Epoch 317/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8765 - val_loss: 0.6227 - val_accuracy: 0.7406\n",
      "Epoch 318/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8812 - val_loss: 0.5848 - val_accuracy: 0.7531\n",
      "Epoch 319/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2740 - accuracy: 0.8890 - val_loss: 0.5876 - val_accuracy: 0.7719\n",
      "Epoch 320/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8874 - val_loss: 0.5769 - val_accuracy: 0.7656\n",
      "Epoch 321/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8890 - val_loss: 0.6061 - val_accuracy: 0.7750\n",
      "Epoch 322/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2875 - accuracy: 0.8804 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 323/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2834 - accuracy: 0.8788 - val_loss: 0.5842 - val_accuracy: 0.7781\n",
      "Epoch 324/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.8812 - val_loss: 0.5957 - val_accuracy: 0.7594\n",
      "Epoch 325/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8898 - val_loss: 0.6127 - val_accuracy: 0.7781\n",
      "Epoch 326/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.8866 - val_loss: 0.5877 - val_accuracy: 0.7563\n",
      "Epoch 327/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2758 - accuracy: 0.8772 - val_loss: 0.6173 - val_accuracy: 0.7781\n",
      "Epoch 328/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2824 - accuracy: 0.8843 - val_loss: 0.5959 - val_accuracy: 0.7781\n",
      "Epoch 329/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.8866 - val_loss: 0.6057 - val_accuracy: 0.7594\n",
      "Epoch 330/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.8905 - val_loss: 0.5904 - val_accuracy: 0.7781\n",
      "Epoch 331/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8858 - val_loss: 0.5997 - val_accuracy: 0.7625\n",
      "Epoch 332/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8882 - val_loss: 0.5823 - val_accuracy: 0.7781\n",
      "Epoch 333/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.8960 - val_loss: 0.5830 - val_accuracy: 0.7719\n",
      "Epoch 334/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.8898 - val_loss: 0.6174 - val_accuracy: 0.7688\n",
      "Epoch 335/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.8819 - val_loss: 0.6043 - val_accuracy: 0.7656\n",
      "Epoch 336/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8843 - val_loss: 0.6467 - val_accuracy: 0.7500\n",
      "Epoch 337/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8804 - val_loss: 0.6005 - val_accuracy: 0.7563\n",
      "Epoch 338/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8905 - val_loss: 0.6057 - val_accuracy: 0.7844\n",
      "Epoch 339/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.8858 - val_loss: 0.6039 - val_accuracy: 0.7688\n",
      "Epoch 340/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2686 - accuracy: 0.8898 - val_loss: 0.5958 - val_accuracy: 0.7781\n",
      "Epoch 341/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8749 - val_loss: 0.6035 - val_accuracy: 0.7719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8905 - val_loss: 0.6228 - val_accuracy: 0.7844\n",
      "Epoch 343/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.8835 - val_loss: 0.6154 - val_accuracy: 0.7719\n",
      "Epoch 344/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.8890 - val_loss: 0.5881 - val_accuracy: 0.7781\n",
      "Epoch 345/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2681 - accuracy: 0.8952 - val_loss: 0.6080 - val_accuracy: 0.7937\n",
      "Epoch 346/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2679 - accuracy: 0.8921 - val_loss: 0.5984 - val_accuracy: 0.7781\n",
      "Epoch 347/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8874 - val_loss: 0.6365 - val_accuracy: 0.7656\n",
      "Epoch 348/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.8937 - val_loss: 0.6365 - val_accuracy: 0.7781\n",
      "Epoch 349/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2647 - accuracy: 0.8890 - val_loss: 0.5941 - val_accuracy: 0.7656\n",
      "Epoch 350/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2610 - accuracy: 0.8866 - val_loss: 0.6057 - val_accuracy: 0.7750\n",
      "Epoch 351/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.8937 - val_loss: 0.6146 - val_accuracy: 0.7812\n",
      "Epoch 352/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.88 - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8772 - val_loss: 0.6065 - val_accuracy: 0.7844\n",
      "Epoch 353/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.8866 - val_loss: 0.6195 - val_accuracy: 0.7781\n",
      "Epoch 354/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8929 - val_loss: 0.6380 - val_accuracy: 0.7719\n",
      "Epoch 355/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.8898 - val_loss: 0.6567 - val_accuracy: 0.7812\n",
      "Epoch 356/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2891 - accuracy: 0.8796 - val_loss: 0.6075 - val_accuracy: 0.7937\n",
      "Epoch 357/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2625 - accuracy: 0.8905 - val_loss: 0.6373 - val_accuracy: 0.7781\n",
      "Epoch 358/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2637 - accuracy: 0.8999 - val_loss: 0.6246 - val_accuracy: 0.7781\n",
      "Epoch 359/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.8905 - val_loss: 0.6333 - val_accuracy: 0.7781\n",
      "Epoch 360/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.8999 - val_loss: 0.6642 - val_accuracy: 0.7563\n",
      "Epoch 361/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.9015 - val_loss: 0.6361 - val_accuracy: 0.7812\n",
      "Epoch 362/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2567 - accuracy: 0.8960 - val_loss: 0.6242 - val_accuracy: 0.7719\n",
      "Epoch 363/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.8921 - val_loss: 0.6266 - val_accuracy: 0.7688\n",
      "Epoch 364/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.8898 - val_loss: 0.6296 - val_accuracy: 0.7844\n",
      "Epoch 365/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2570 - accuracy: 0.8984 - val_loss: 0.6696 - val_accuracy: 0.7563\n",
      "Epoch 366/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.8984 - val_loss: 0.6258 - val_accuracy: 0.7906\n",
      "Epoch 367/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2554 - accuracy: 0.8944 - val_loss: 0.6220 - val_accuracy: 0.7844\n",
      "Epoch 368/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.8898 - val_loss: 0.6451 - val_accuracy: 0.7781\n",
      "Epoch 369/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.9015 - val_loss: 0.6392 - val_accuracy: 0.7875\n",
      "Epoch 370/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.9007 - val_loss: 0.6216 - val_accuracy: 0.7750\n",
      "Epoch 371/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8890 - val_loss: 0.6225 - val_accuracy: 0.7719\n",
      "Epoch 372/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.8866 - val_loss: 0.6316 - val_accuracy: 0.7875\n",
      "Epoch 373/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8968 - val_loss: 0.6022 - val_accuracy: 0.7750\n",
      "Epoch 374/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.8960 - val_loss: 0.6348 - val_accuracy: 0.7719\n",
      "Epoch 375/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2586 - accuracy: 0.8905 - val_loss: 0.6205 - val_accuracy: 0.7781\n",
      "Epoch 376/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9046 - val_loss: 0.6358 - val_accuracy: 0.7812\n",
      "Epoch 377/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.8952 - val_loss: 0.6265 - val_accuracy: 0.7594\n",
      "Epoch 378/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9054 - val_loss: 0.6319 - val_accuracy: 0.7781\n",
      "Epoch 379/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8999 - val_loss: 0.6545 - val_accuracy: 0.7688\n",
      "Epoch 380/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.9062 - val_loss: 0.6173 - val_accuracy: 0.7750\n",
      "Epoch 381/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.8944 - val_loss: 0.6385 - val_accuracy: 0.7719\n",
      "Epoch 382/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.8921 - val_loss: 0.6114 - val_accuracy: 0.7719\n",
      "Epoch 383/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.8937 - val_loss: 0.6302 - val_accuracy: 0.7750\n",
      "Epoch 384/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8929 - val_loss: 0.6440 - val_accuracy: 0.7937\n",
      "Epoch 385/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8984 - val_loss: 0.6003 - val_accuracy: 0.7875\n",
      "Epoch 386/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9030 - val_loss: 0.6336 - val_accuracy: 0.7656\n",
      "Epoch 387/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2577 - accuracy: 0.9054 - val_loss: 0.6432 - val_accuracy: 0.7844\n",
      "Epoch 388/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.8937 - val_loss: 0.6502 - val_accuracy: 0.7812\n",
      "Epoch 389/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8929 - val_loss: 0.6376 - val_accuracy: 0.7812\n",
      "Epoch 390/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.9062 - val_loss: 0.6357 - val_accuracy: 0.7844\n",
      "Epoch 391/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.9030 - val_loss: 0.6408 - val_accuracy: 0.7719\n",
      "Epoch 392/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.9007 - val_loss: 0.6367 - val_accuracy: 0.7781\n",
      "Epoch 393/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.8999 - val_loss: 0.6340 - val_accuracy: 0.7625\n",
      "Epoch 394/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8991 - val_loss: 0.6124 - val_accuracy: 0.7750\n",
      "Epoch 395/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8929 - val_loss: 0.6327 - val_accuracy: 0.7875\n",
      "Epoch 396/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.8991 - val_loss: 0.6700 - val_accuracy: 0.7688\n",
      "Epoch 397/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8929 - val_loss: 0.6439 - val_accuracy: 0.7781\n",
      "Epoch 398/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9023 - val_loss: 0.6485 - val_accuracy: 0.7937\n",
      "Epoch 399/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.8960 - val_loss: 0.6604 - val_accuracy: 0.7906\n",
      "Epoch 400/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.9062 - val_loss: 0.6363 - val_accuracy: 0.7688\n",
      "Epoch 401/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9038 - val_loss: 0.6411 - val_accuracy: 0.7625\n",
      "Epoch 402/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.9085 - val_loss: 0.6327 - val_accuracy: 0.7812\n",
      "Epoch 403/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9046 - val_loss: 0.6446 - val_accuracy: 0.7906\n",
      "Epoch 404/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2399 - accuracy: 0.9070 - val_loss: 0.6607 - val_accuracy: 0.7656\n",
      "Epoch 405/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9077 - val_loss: 0.6349 - val_accuracy: 0.7781\n",
      "Epoch 406/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9023 - val_loss: 0.7084 - val_accuracy: 0.7594\n",
      "Epoch 407/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.8960 - val_loss: 0.6735 - val_accuracy: 0.7688\n",
      "Epoch 408/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.9023 - val_loss: 0.6457 - val_accuracy: 0.7875\n",
      "Epoch 409/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9124 - val_loss: 0.6677 - val_accuracy: 0.7812\n",
      "Epoch 410/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.9015 - val_loss: 0.6817 - val_accuracy: 0.7750\n",
      "Epoch 411/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.8976 - val_loss: 0.6599 - val_accuracy: 0.7781\n",
      "Epoch 412/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.9070 - val_loss: 0.6798 - val_accuracy: 0.7688\n",
      "Epoch 413/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.9038 - val_loss: 0.6773 - val_accuracy: 0.7719\n",
      "Epoch 414/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2544 - accuracy: 0.8898 - val_loss: 0.6623 - val_accuracy: 0.7719\n",
      "Epoch 415/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2430 - accuracy: 0.8991 - val_loss: 0.6488 - val_accuracy: 0.7500\n",
      "Epoch 416/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9132 - val_loss: 0.6409 - val_accuracy: 0.7781\n",
      "Epoch 417/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9062 - val_loss: 0.6899 - val_accuracy: 0.7531\n",
      "Epoch 418/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9046 - val_loss: 0.6599 - val_accuracy: 0.7688\n",
      "Epoch 419/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9101 - val_loss: 0.6578 - val_accuracy: 0.7750\n",
      "Epoch 420/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9093 - val_loss: 0.6687 - val_accuracy: 0.7750\n",
      "Epoch 421/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.9030 - val_loss: 0.6447 - val_accuracy: 0.7906\n",
      "Epoch 422/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9085 - val_loss: 0.6524 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9030 - val_loss: 0.6731 - val_accuracy: 0.7594\n",
      "Epoch 424/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.9054 - val_loss: 0.6547 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9116 - val_loss: 0.6832 - val_accuracy: 0.7812\n",
      "Epoch 426/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9054 - val_loss: 0.7168 - val_accuracy: 0.7750\n",
      "Epoch 427/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9163 - val_loss: 0.6708 - val_accuracy: 0.7719\n",
      "Epoch 428/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2320 - accuracy: 0.9077 - val_loss: 0.6549 - val_accuracy: 0.7812\n",
      "Epoch 429/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9085 - val_loss: 0.6626 - val_accuracy: 0.7812\n",
      "Epoch 430/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9093 - val_loss: 0.6843 - val_accuracy: 0.7688\n",
      "Epoch 431/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9093 - val_loss: 0.6486 - val_accuracy: 0.7844\n",
      "Epoch 432/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.9101 - val_loss: 0.6747 - val_accuracy: 0.7750\n",
      "Epoch 433/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9109 - val_loss: 0.6604 - val_accuracy: 0.7719\n",
      "Epoch 434/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9070 - val_loss: 0.6956 - val_accuracy: 0.7719\n",
      "Epoch 435/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9062 - val_loss: 0.6751 - val_accuracy: 0.7688\n",
      "Epoch 436/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9140 - val_loss: 0.6682 - val_accuracy: 0.7875\n",
      "Epoch 437/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9077 - val_loss: 0.6961 - val_accuracy: 0.7719\n",
      "Epoch 438/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9085 - val_loss: 0.6671 - val_accuracy: 0.7781\n",
      "Epoch 439/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9195 - val_loss: 0.6840 - val_accuracy: 0.7844\n",
      "Epoch 440/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9085 - val_loss: 0.7077 - val_accuracy: 0.7750\n",
      "Epoch 441/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9140 - val_loss: 0.6728 - val_accuracy: 0.7750\n",
      "Epoch 442/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9101 - val_loss: 0.6972 - val_accuracy: 0.7719\n",
      "Epoch 443/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2213 - accuracy: 0.9148 - val_loss: 0.6815 - val_accuracy: 0.7875\n",
      "Epoch 444/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.9109 - val_loss: 0.6767 - val_accuracy: 0.7781\n",
      "Epoch 445/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.9030 - val_loss: 0.7015 - val_accuracy: 0.7844\n",
      "Epoch 446/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9093 - val_loss: 0.7050 - val_accuracy: 0.7719\n",
      "Epoch 447/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.9179 - val_loss: 0.6783 - val_accuracy: 0.7781\n",
      "Epoch 448/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9116 - val_loss: 0.6998 - val_accuracy: 0.7750\n",
      "Epoch 449/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.8976 - val_loss: 0.6920 - val_accuracy: 0.7688\n",
      "Epoch 450/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.9046 - val_loss: 0.6782 - val_accuracy: 0.7719\n",
      "Epoch 451/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2228 - accuracy: 0.9171 - val_loss: 0.6952 - val_accuracy: 0.7781\n",
      "Epoch 452/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9132 - val_loss: 0.7062 - val_accuracy: 0.7875\n",
      "Epoch 453/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9179 - val_loss: 0.6675 - val_accuracy: 0.7875\n",
      "Epoch 454/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2259 - accuracy: 0.9085 - val_loss: 0.6915 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9163 - val_loss: 0.7052 - val_accuracy: 0.7719\n",
      "Epoch 456/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9132 - val_loss: 0.6901 - val_accuracy: 0.7750\n",
      "Epoch 457/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.9070 - val_loss: 0.6966 - val_accuracy: 0.7812\n",
      "Epoch 458/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2189 - accuracy: 0.9171 - val_loss: 0.7121 - val_accuracy: 0.7969\n",
      "Epoch 459/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9077 - val_loss: 0.7203 - val_accuracy: 0.7719\n",
      "Epoch 460/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9156 - val_loss: 0.7132 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9249 - val_loss: 0.7271 - val_accuracy: 0.7500\n",
      "Epoch 462/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9179 - val_loss: 0.6982 - val_accuracy: 0.7875\n",
      "Epoch 463/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.9023 - val_loss: 0.7056 - val_accuracy: 0.7688\n",
      "Epoch 464/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9210 - val_loss: 0.7006 - val_accuracy: 0.7875\n",
      "Epoch 465/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2202 - accuracy: 0.9109 - val_loss: 0.6974 - val_accuracy: 0.7906\n",
      "Epoch 466/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.9187 - val_loss: 0.7225 - val_accuracy: 0.7688\n",
      "Epoch 467/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9077 - val_loss: 0.6952 - val_accuracy: 0.7719\n",
      "Epoch 468/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2170 - accuracy: 0.9187 - val_loss: 0.7294 - val_accuracy: 0.7781\n",
      "Epoch 469/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9101 - val_loss: 0.6896 - val_accuracy: 0.7719\n",
      "Epoch 470/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9124 - val_loss: 0.7300 - val_accuracy: 0.7875\n",
      "Epoch 471/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9187 - val_loss: 0.6834 - val_accuracy: 0.7688\n",
      "Epoch 472/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9140 - val_loss: 0.7623 - val_accuracy: 0.7437\n",
      "Epoch 473/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9140 - val_loss: 0.7719 - val_accuracy: 0.7719\n",
      "Epoch 474/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9116 - val_loss: 0.7286 - val_accuracy: 0.7500\n",
      "Epoch 475/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.9148 - val_loss: 0.7248 - val_accuracy: 0.7750\n",
      "Epoch 476/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.9109 - val_loss: 0.7114 - val_accuracy: 0.7969\n",
      "Epoch 477/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9171 - val_loss: 0.7281 - val_accuracy: 0.7750\n",
      "Epoch 478/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.9163 - val_loss: 0.7486 - val_accuracy: 0.7812\n",
      "Epoch 479/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9187 - val_loss: 0.7242 - val_accuracy: 0.7625\n",
      "Epoch 480/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9062 - val_loss: 0.7501 - val_accuracy: 0.8000\n",
      "Epoch 481/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.9116 - val_loss: 0.7220 - val_accuracy: 0.7719\n",
      "Epoch 482/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9148 - val_loss: 0.7263 - val_accuracy: 0.7719\n",
      "Epoch 483/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9218 - val_loss: 0.7376 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.2183 - accuracy: 0.9093 - val_loss: 0.7218 - val_accuracy: 0.7719\n",
      "Epoch 485/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9296 - val_loss: 0.7254 - val_accuracy: 0.7719\n",
      "Epoch 486/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9116 - val_loss: 0.6974 - val_accuracy: 0.7781\n",
      "Epoch 487/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9203 - val_loss: 0.7125 - val_accuracy: 0.7594\n",
      "Epoch 488/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9085 - val_loss: 0.7261 - val_accuracy: 0.7875\n",
      "Epoch 489/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.9093 - val_loss: 0.7014 - val_accuracy: 0.7781\n",
      "Epoch 490/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.9203 - val_loss: 0.7347 - val_accuracy: 0.7719\n",
      "Epoch 491/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9171 - val_loss: 0.7479 - val_accuracy: 0.7812\n",
      "Epoch 492/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9195 - val_loss: 0.7245 - val_accuracy: 0.7875\n",
      "Epoch 493/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9179 - val_loss: 0.7367 - val_accuracy: 0.7719\n",
      "Epoch 494/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9210 - val_loss: 0.7285 - val_accuracy: 0.7844\n",
      "Epoch 495/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9195 - val_loss: 0.7433 - val_accuracy: 0.7781\n",
      "Epoch 496/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9163 - val_loss: 0.7317 - val_accuracy: 0.7781\n",
      "Epoch 497/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9249 - val_loss: 0.7175 - val_accuracy: 0.7781\n",
      "Epoch 498/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9335 - val_loss: 0.7593 - val_accuracy: 0.7531\n",
      "Epoch 499/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9156 - val_loss: 0.7556 - val_accuracy: 0.7563\n",
      "Epoch 500/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.9257 - val_loss: 0.7565 - val_accuracy: 0.7844\n",
      "Epoch 501/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9242 - val_loss: 0.7314 - val_accuracy: 0.7781\n",
      "Epoch 502/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9203 - val_loss: 0.7360 - val_accuracy: 0.7781\n",
      "Epoch 503/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9148 - val_loss: 0.7509 - val_accuracy: 0.7719\n",
      "Epoch 504/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9179 - val_loss: 0.7587 - val_accuracy: 0.7688\n",
      "Epoch 505/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9242 - val_loss: 0.8051 - val_accuracy: 0.7625\n",
      "Epoch 506/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9163 - val_loss: 0.7462 - val_accuracy: 0.7781\n",
      "Epoch 507/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9210 - val_loss: 0.7524 - val_accuracy: 0.7719\n",
      "Epoch 508/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1966 - accuracy: 0.9249 - val_loss: 0.7384 - val_accuracy: 0.7812\n",
      "Epoch 509/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9203 - val_loss: 0.7372 - val_accuracy: 0.7906\n",
      "Epoch 510/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2037 - accuracy: 0.9226 - val_loss: 0.7622 - val_accuracy: 0.7719\n",
      "Epoch 511/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9148 - val_loss: 0.7577 - val_accuracy: 0.7563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2042 - accuracy: 0.9187 - val_loss: 0.7595 - val_accuracy: 0.7844\n",
      "Epoch 513/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9101 - val_loss: 0.7537 - val_accuracy: 0.7812\n",
      "Epoch 514/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9156 - val_loss: 0.7240 - val_accuracy: 0.7781\n",
      "Epoch 515/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9265 - val_loss: 0.7602 - val_accuracy: 0.7750\n",
      "Epoch 516/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9242 - val_loss: 0.7711 - val_accuracy: 0.7625\n",
      "Epoch 517/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2019 - accuracy: 0.9179 - val_loss: 0.7414 - val_accuracy: 0.7750\n",
      "Epoch 518/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1987 - accuracy: 0.9320 - val_loss: 0.7790 - val_accuracy: 0.7875\n",
      "Epoch 519/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9132 - val_loss: 0.7707 - val_accuracy: 0.7906\n",
      "Epoch 520/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9210 - val_loss: 0.7762 - val_accuracy: 0.7719\n",
      "Epoch 521/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9226 - val_loss: 0.7556 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1927 - accuracy: 0.9289 - val_loss: 0.7822 - val_accuracy: 0.7750\n",
      "Epoch 523/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1964 - accuracy: 0.9273 - val_loss: 0.7726 - val_accuracy: 0.7781\n",
      "Epoch 524/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9203 - val_loss: 0.7716 - val_accuracy: 0.7750\n",
      "Epoch 525/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9226 - val_loss: 0.7744 - val_accuracy: 0.7781\n",
      "Epoch 526/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1934 - accuracy: 0.9273 - val_loss: 0.7836 - val_accuracy: 0.7781\n",
      "Epoch 527/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9312 - val_loss: 0.7909 - val_accuracy: 0.7625\n",
      "Epoch 528/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1931 - accuracy: 0.9242 - val_loss: 0.7810 - val_accuracy: 0.7563\n",
      "Epoch 529/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9257 - val_loss: 0.8160 - val_accuracy: 0.7750\n",
      "Epoch 530/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9187 - val_loss: 0.7824 - val_accuracy: 0.7750\n",
      "Epoch 531/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9242 - val_loss: 0.7797 - val_accuracy: 0.8000\n",
      "Epoch 532/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9281 - val_loss: 0.7629 - val_accuracy: 0.7688\n",
      "Epoch 533/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9289 - val_loss: 0.7866 - val_accuracy: 0.7719\n",
      "Epoch 534/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9242 - val_loss: 0.7990 - val_accuracy: 0.7750\n",
      "Epoch 535/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9265 - val_loss: 0.7686 - val_accuracy: 0.7781\n",
      "Epoch 536/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1996 - accuracy: 0.9242 - val_loss: 0.7731 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9249 - val_loss: 0.7898 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1903 - accuracy: 0.9281 - val_loss: 0.8104 - val_accuracy: 0.7781\n",
      "Epoch 539/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2386 - accuracy: 0.9148 - val_loss: 0.7655 - val_accuracy: 0.7812\n",
      "Epoch 540/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9226 - val_loss: 0.8123 - val_accuracy: 0.7844\n",
      "Epoch 541/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9195 - val_loss: 0.8003 - val_accuracy: 0.7688\n",
      "Epoch 542/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9296 - val_loss: 0.8191 - val_accuracy: 0.7750\n",
      "Epoch 543/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9249 - val_loss: 0.7713 - val_accuracy: 0.7844\n",
      "Epoch 544/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1909 - accuracy: 0.9249 - val_loss: 0.7668 - val_accuracy: 0.7781\n",
      "Epoch 545/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9289 - val_loss: 0.7713 - val_accuracy: 0.7812\n",
      "Epoch 546/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1945 - accuracy: 0.9203 - val_loss: 0.7736 - val_accuracy: 0.7875\n",
      "Epoch 547/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1919 - accuracy: 0.9234 - val_loss: 0.7719 - val_accuracy: 0.7781\n",
      "Epoch 548/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9242 - val_loss: 0.7847 - val_accuracy: 0.7594\n",
      "Epoch 549/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1970 - accuracy: 0.9249 - val_loss: 0.7947 - val_accuracy: 0.7812\n",
      "Epoch 550/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1863 - accuracy: 0.9320 - val_loss: 0.7510 - val_accuracy: 0.7875\n",
      "Epoch 551/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1844 - accuracy: 0.9328 - val_loss: 0.7914 - val_accuracy: 0.7719\n",
      "Epoch 552/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1844 - accuracy: 0.9328 - val_loss: 0.7951 - val_accuracy: 0.7906\n",
      "Epoch 553/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.1885 - accuracy: 0.9304 - val_loss: 0.7947 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.1975 - accuracy: 0.9179 - val_loss: 0.7768 - val_accuracy: 0.7594\n",
      "Epoch 555/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9273 - val_loss: 0.7732 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1973 - accuracy: 0.9234 - val_loss: 0.8097 - val_accuracy: 0.7688\n",
      "Epoch 557/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1957 - accuracy: 0.9281 - val_loss: 0.7708 - val_accuracy: 0.7781\n",
      "Epoch 558/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1803 - accuracy: 0.9359 - val_loss: 0.7920 - val_accuracy: 0.7875\n",
      "Epoch 559/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.9257 - val_loss: 0.7892 - val_accuracy: 0.7625\n",
      "Epoch 560/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9265 - val_loss: 0.7983 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9226 - val_loss: 0.7789 - val_accuracy: 0.7844\n",
      "Epoch 562/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9320 - val_loss: 0.8107 - val_accuracy: 0.7625\n",
      "Epoch 563/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1927 - accuracy: 0.9249 - val_loss: 0.8243 - val_accuracy: 0.7594\n",
      "Epoch 564/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1930 - accuracy: 0.9226 - val_loss: 0.7666 - val_accuracy: 0.7750\n",
      "Epoch 565/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.9273 - val_loss: 0.7911 - val_accuracy: 0.7688\n",
      "Epoch 566/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9249 - val_loss: 0.7947 - val_accuracy: 0.7750\n",
      "Epoch 567/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9249 - val_loss: 0.7875 - val_accuracy: 0.7688\n",
      "Epoch 568/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1936 - accuracy: 0.9273 - val_loss: 0.7799 - val_accuracy: 0.7781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9320 - val_loss: 0.7942 - val_accuracy: 0.7906\n",
      "Epoch 570/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1942 - accuracy: 0.9234 - val_loss: 0.7931 - val_accuracy: 0.7812\n",
      "Epoch 571/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.9109 - val_loss: 0.8239 - val_accuracy: 0.7688\n",
      "Epoch 572/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9265 - val_loss: 0.8151 - val_accuracy: 0.7750\n",
      "Epoch 573/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9320 - val_loss: 0.8066 - val_accuracy: 0.7844\n",
      "Epoch 574/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9273 - val_loss: 0.8387 - val_accuracy: 0.7781\n",
      "Epoch 575/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.9257 - val_loss: 0.8057 - val_accuracy: 0.7625\n",
      "Epoch 576/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1844 - accuracy: 0.9328 - val_loss: 0.7990 - val_accuracy: 0.7719\n",
      "Epoch 577/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1804 - accuracy: 0.9304 - val_loss: 0.8361 - val_accuracy: 0.7781\n",
      "Epoch 578/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9242 - val_loss: 0.8328 - val_accuracy: 0.7781\n",
      "Epoch 579/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9249 - val_loss: 0.7904 - val_accuracy: 0.7844\n",
      "Epoch 580/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9226 - val_loss: 0.8215 - val_accuracy: 0.7906\n",
      "Epoch 581/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9351 - val_loss: 0.8028 - val_accuracy: 0.7906\n",
      "Epoch 582/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9359 - val_loss: 0.7962 - val_accuracy: 0.7844\n",
      "Epoch 583/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9359 - val_loss: 0.8089 - val_accuracy: 0.7844\n",
      "Epoch 584/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9367 - val_loss: 0.8447 - val_accuracy: 0.7656\n",
      "Epoch 585/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9367 - val_loss: 0.8462 - val_accuracy: 0.7719\n",
      "Epoch 586/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9343 - val_loss: 0.7985 - val_accuracy: 0.7844\n",
      "Epoch 587/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9281 - val_loss: 0.7971 - val_accuracy: 0.7906\n",
      "Epoch 588/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9343 - val_loss: 0.8355 - val_accuracy: 0.7750\n",
      "Epoch 589/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9210 - val_loss: 0.8135 - val_accuracy: 0.7844\n",
      "Epoch 590/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9312 - val_loss: 0.8396 - val_accuracy: 0.7750\n",
      "Epoch 591/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9351 - val_loss: 0.8474 - val_accuracy: 0.7719\n",
      "Epoch 592/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9328 - val_loss: 0.8218 - val_accuracy: 0.7937\n",
      "Epoch 593/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9335 - val_loss: 0.8764 - val_accuracy: 0.7969\n",
      "Epoch 594/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1852 - accuracy: 0.9249 - val_loss: 0.8329 - val_accuracy: 0.7875\n",
      "Epoch 595/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9320 - val_loss: 0.8182 - val_accuracy: 0.7812\n",
      "Epoch 596/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9304 - val_loss: 0.8618 - val_accuracy: 0.7625\n",
      "Epoch 597/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9257 - val_loss: 0.8223 - val_accuracy: 0.7844\n",
      "Epoch 598/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9226 - val_loss: 0.8229 - val_accuracy: 0.7750\n",
      "Epoch 599/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9289 - val_loss: 0.8116 - val_accuracy: 0.7781\n",
      "Epoch 600/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9242 - val_loss: 0.8383 - val_accuracy: 0.7844\n",
      "Epoch 601/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9367 - val_loss: 0.8595 - val_accuracy: 0.7750\n",
      "Epoch 602/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9335 - val_loss: 0.8538 - val_accuracy: 0.7719\n",
      "Epoch 603/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1781 - accuracy: 0.9273 - val_loss: 0.8516 - val_accuracy: 0.7844\n",
      "Epoch 604/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9304 - val_loss: 0.8467 - val_accuracy: 0.7719\n",
      "Epoch 605/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9210 - val_loss: 0.8631 - val_accuracy: 0.7781\n",
      "Epoch 606/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9390 - val_loss: 0.8323 - val_accuracy: 0.7812\n",
      "Epoch 607/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9312 - val_loss: 0.8771 - val_accuracy: 0.7594\n",
      "Epoch 608/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9367 - val_loss: 0.9175 - val_accuracy: 0.7625\n",
      "Epoch 609/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9359 - val_loss: 0.8472 - val_accuracy: 0.7812\n",
      "Epoch 610/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9367 - val_loss: 0.8420 - val_accuracy: 0.7781\n",
      "Epoch 611/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9281 - val_loss: 0.8729 - val_accuracy: 0.7625\n",
      "Epoch 612/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9343 - val_loss: 0.8225 - val_accuracy: 0.7656\n",
      "Epoch 613/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9281 - val_loss: 0.8382 - val_accuracy: 0.7688\n",
      "Epoch 614/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9328 - val_loss: 0.8800 - val_accuracy: 0.7719\n",
      "Epoch 615/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9375 - val_loss: 0.8431 - val_accuracy: 0.7719\n",
      "Epoch 616/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9398 - val_loss: 0.8638 - val_accuracy: 0.7719\n",
      "Epoch 617/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9312 - val_loss: 0.8364 - val_accuracy: 0.7688\n",
      "Epoch 618/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1695 - accuracy: 0.9375 - val_loss: 0.8402 - val_accuracy: 0.7906\n",
      "Epoch 619/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1701 - accuracy: 0.9343 - val_loss: 0.8380 - val_accuracy: 0.7750\n",
      "Epoch 620/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1707 - accuracy: 0.9375 - val_loss: 0.8720 - val_accuracy: 0.7781\n",
      "Epoch 621/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9343 - val_loss: 0.8952 - val_accuracy: 0.7594\n",
      "Epoch 622/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1776 - accuracy: 0.9226 - val_loss: 0.8762 - val_accuracy: 0.7688\n",
      "Epoch 623/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.9359 - val_loss: 0.8703 - val_accuracy: 0.7750\n",
      "Epoch 624/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9312 - val_loss: 0.8974 - val_accuracy: 0.7625\n",
      "Epoch 625/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9296 - val_loss: 0.8771 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1750 - accuracy: 0.9257 - val_loss: 0.8597 - val_accuracy: 0.7875\n",
      "Epoch 627/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9421 - val_loss: 0.8929 - val_accuracy: 0.7531\n",
      "Epoch 628/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1853 - accuracy: 0.9281 - val_loss: 0.9147 - val_accuracy: 0.7750\n",
      "Epoch 629/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9312 - val_loss: 0.8850 - val_accuracy: 0.7875\n",
      "Epoch 630/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9335 - val_loss: 0.8823 - val_accuracy: 0.7812\n",
      "Epoch 631/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9429 - val_loss: 0.9013 - val_accuracy: 0.7688\n",
      "Epoch 632/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1713 - accuracy: 0.9320 - val_loss: 0.8820 - val_accuracy: 0.7625\n",
      "Epoch 633/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9328 - val_loss: 0.8615 - val_accuracy: 0.7875\n",
      "Epoch 634/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9390 - val_loss: 0.9077 - val_accuracy: 0.7750\n",
      "Epoch 635/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9289 - val_loss: 0.8757 - val_accuracy: 0.7812\n",
      "Epoch 636/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9234 - val_loss: 0.8899 - val_accuracy: 0.7594\n",
      "Epoch 637/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9218 - val_loss: 0.9091 - val_accuracy: 0.7688\n",
      "Epoch 638/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.9320 - val_loss: 1.0282 - val_accuracy: 0.7688\n",
      "Epoch 639/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9218 - val_loss: 0.9156 - val_accuracy: 0.7531\n",
      "Epoch 640/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9375 - val_loss: 0.8629 - val_accuracy: 0.7781\n",
      "Epoch 641/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9398 - val_loss: 0.8617 - val_accuracy: 0.7781\n",
      "Epoch 642/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9328 - val_loss: 0.8731 - val_accuracy: 0.7719\n",
      "Epoch 643/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9390 - val_loss: 0.8736 - val_accuracy: 0.7750\n",
      "Epoch 644/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9359 - val_loss: 0.8837 - val_accuracy: 0.7750\n",
      "Epoch 645/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9414 - val_loss: 0.8752 - val_accuracy: 0.7844\n",
      "Epoch 646/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9437 - val_loss: 0.8851 - val_accuracy: 0.7563\n",
      "Epoch 647/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9351 - val_loss: 0.8826 - val_accuracy: 0.7688\n",
      "Epoch 648/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9328 - val_loss: 0.8701 - val_accuracy: 0.7781\n",
      "Epoch 649/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9437 - val_loss: 0.8775 - val_accuracy: 0.7719\n",
      "Epoch 650/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 0.9414 - val_loss: 0.8749 - val_accuracy: 0.7656\n",
      "Epoch 651/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9414 - val_loss: 0.8881 - val_accuracy: 0.7781\n",
      "Epoch 652/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9343 - val_loss: 0.8910 - val_accuracy: 0.7781\n",
      "Epoch 653/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9390 - val_loss: 0.8564 - val_accuracy: 0.7812\n",
      "Epoch 654/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1692 - accuracy: 0.9320 - val_loss: 0.8908 - val_accuracy: 0.7719\n",
      "Epoch 655/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9375 - val_loss: 0.8690 - val_accuracy: 0.7937\n",
      "Epoch 656/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9296 - val_loss: 0.8726 - val_accuracy: 0.7750\n",
      "Epoch 657/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9421 - val_loss: 0.8826 - val_accuracy: 0.7844\n",
      "Epoch 658/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9453 - val_loss: 0.9070 - val_accuracy: 0.7688\n",
      "Epoch 659/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9398 - val_loss: 0.8764 - val_accuracy: 0.7750\n",
      "Epoch 660/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9453 - val_loss: 0.9457 - val_accuracy: 0.7531\n",
      "Epoch 661/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9375 - val_loss: 0.9100 - val_accuracy: 0.7781\n",
      "Epoch 662/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9249 - val_loss: 0.9238 - val_accuracy: 0.7844\n",
      "Epoch 663/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9461 - val_loss: 0.8982 - val_accuracy: 0.7750\n",
      "Epoch 664/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9296 - val_loss: 0.8862 - val_accuracy: 0.7906\n",
      "Epoch 665/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9398 - val_loss: 0.9013 - val_accuracy: 0.7781\n",
      "Epoch 666/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 0.9398 - val_loss: 0.9097 - val_accuracy: 0.7875\n",
      "Epoch 667/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9359 - val_loss: 0.8990 - val_accuracy: 0.7656\n",
      "Epoch 668/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.9359 - val_loss: 0.9152 - val_accuracy: 0.7719\n",
      "Epoch 669/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9343 - val_loss: 0.8935 - val_accuracy: 0.7844\n",
      "Epoch 670/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9421 - val_loss: 0.8944 - val_accuracy: 0.7844\n",
      "Epoch 671/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9414 - val_loss: 0.9000 - val_accuracy: 0.7844\n",
      "Epoch 672/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9406 - val_loss: 0.9277 - val_accuracy: 0.7937\n",
      "Epoch 673/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9390 - val_loss: 0.9228 - val_accuracy: 0.7688\n",
      "Epoch 674/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9375 - val_loss: 0.9183 - val_accuracy: 0.7844\n",
      "Epoch 675/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9351 - val_loss: 0.8871 - val_accuracy: 0.7781\n",
      "Epoch 676/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9359 - val_loss: 0.9512 - val_accuracy: 0.7563\n",
      "Epoch 677/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9320 - val_loss: 0.9273 - val_accuracy: 0.7812\n",
      "Epoch 678/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9398 - val_loss: 0.8843 - val_accuracy: 0.7812\n",
      "Epoch 679/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1569 - accuracy: 0.9461 - val_loss: 0.9095 - val_accuracy: 0.7844\n",
      "Epoch 680/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9398 - val_loss: 0.9062 - val_accuracy: 0.7656\n",
      "Epoch 681/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9328 - val_loss: 0.9255 - val_accuracy: 0.7563\n",
      "Epoch 682/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1563 - accuracy: 0.9445 - val_loss: 0.8973 - val_accuracy: 0.7969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9398 - val_loss: 0.9239 - val_accuracy: 0.7844\n",
      "Epoch 684/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9468 - val_loss: 0.9361 - val_accuracy: 0.7656\n",
      "Epoch 685/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9390 - val_loss: 0.9213 - val_accuracy: 0.7844\n",
      "Epoch 686/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9390 - val_loss: 0.8766 - val_accuracy: 0.7906\n",
      "Epoch 687/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1608 - accuracy: 0.9398 - val_loss: 0.9336 - val_accuracy: 0.7750\n",
      "Epoch 688/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9445 - val_loss: 0.9291 - val_accuracy: 0.7594\n",
      "Epoch 689/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9406 - val_loss: 0.9550 - val_accuracy: 0.7812\n",
      "Epoch 690/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9312 - val_loss: 0.9055 - val_accuracy: 0.7844\n",
      "Epoch 691/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1550 - accuracy: 0.9398 - val_loss: 0.9508 - val_accuracy: 0.7781\n",
      "Epoch 692/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1549 - accuracy: 0.9461 - val_loss: 0.9492 - val_accuracy: 0.7563\n",
      "Epoch 693/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9375 - val_loss: 0.9525 - val_accuracy: 0.7625\n",
      "Epoch 694/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9484 - val_loss: 0.9403 - val_accuracy: 0.7875\n",
      "Epoch 695/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9492 - val_loss: 0.9198 - val_accuracy: 0.7719\n",
      "Epoch 696/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9476 - val_loss: 0.9220 - val_accuracy: 0.7750\n",
      "Epoch 697/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9484 - val_loss: 0.9593 - val_accuracy: 0.7812\n",
      "Epoch 698/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9406 - val_loss: 0.9382 - val_accuracy: 0.7563\n",
      "Epoch 699/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9406 - val_loss: 0.9346 - val_accuracy: 0.7906\n",
      "Epoch 700/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9429 - val_loss: 0.9190 - val_accuracy: 0.7781\n",
      "Epoch 701/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9445 - val_loss: 0.9389 - val_accuracy: 0.7688\n",
      "Epoch 702/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9382 - val_loss: 0.9699 - val_accuracy: 0.7656\n",
      "Epoch 703/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9429 - val_loss: 0.9333 - val_accuracy: 0.7875\n",
      "Epoch 704/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9461 - val_loss: 0.9054 - val_accuracy: 0.7844\n",
      "Epoch 705/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9437 - val_loss: 0.9452 - val_accuracy: 0.7719\n",
      "Epoch 706/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9406 - val_loss: 0.9819 - val_accuracy: 0.7594\n",
      "Epoch 707/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9421 - val_loss: 0.9321 - val_accuracy: 0.7750\n",
      "Epoch 708/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9351 - val_loss: 1.0119 - val_accuracy: 0.7594\n",
      "Epoch 709/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9461 - val_loss: 0.9788 - val_accuracy: 0.7937\n",
      "Epoch 710/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9429 - val_loss: 0.9585 - val_accuracy: 0.7563\n",
      "Epoch 711/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9398 - val_loss: 1.0101 - val_accuracy: 0.7594\n",
      "Epoch 712/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9359 - val_loss: 0.9648 - val_accuracy: 0.7812\n",
      "Epoch 713/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9461 - val_loss: 0.9795 - val_accuracy: 0.7719\n",
      "Epoch 714/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9437 - val_loss: 1.0162 - val_accuracy: 0.7844\n",
      "Epoch 715/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9296 - val_loss: 1.0497 - val_accuracy: 0.7656\n",
      "Epoch 716/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9406 - val_loss: 0.9045 - val_accuracy: 0.7844\n",
      "Epoch 717/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9414 - val_loss: 0.9171 - val_accuracy: 0.7750\n",
      "Epoch 718/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9437 - val_loss: 0.9065 - val_accuracy: 0.7875\n",
      "Epoch 719/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9414 - val_loss: 0.9653 - val_accuracy: 0.7563\n",
      "Epoch 720/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1562 - accuracy: 0.9382 - val_loss: 0.9143 - val_accuracy: 0.7750\n",
      "Epoch 721/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9507 - val_loss: 0.9565 - val_accuracy: 0.7656\n",
      "Epoch 722/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9289 - val_loss: 0.9198 - val_accuracy: 0.7906\n",
      "Epoch 723/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9414 - val_loss: 0.9216 - val_accuracy: 0.7656\n",
      "Epoch 724/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9476 - val_loss: 0.9522 - val_accuracy: 0.7812\n",
      "Epoch 725/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9492 - val_loss: 0.9400 - val_accuracy: 0.7719\n",
      "Epoch 726/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9476 - val_loss: 0.9360 - val_accuracy: 0.7625\n",
      "Epoch 727/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9500 - val_loss: 0.9578 - val_accuracy: 0.7750\n",
      "Epoch 728/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9492 - val_loss: 0.9437 - val_accuracy: 0.7719\n",
      "Epoch 729/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9461 - val_loss: 0.9340 - val_accuracy: 0.7750\n",
      "Epoch 730/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9453 - val_loss: 0.9475 - val_accuracy: 0.7781\n",
      "Epoch 731/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9476 - val_loss: 0.9495 - val_accuracy: 0.7844\n",
      "Epoch 732/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9515 - val_loss: 0.9579 - val_accuracy: 0.7531\n",
      "Epoch 733/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9492 - val_loss: 0.9591 - val_accuracy: 0.7781\n",
      "Epoch 734/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9507 - val_loss: 0.9696 - val_accuracy: 0.7656\n",
      "Epoch 735/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9531 - val_loss: 0.9260 - val_accuracy: 0.7750\n",
      "Epoch 736/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9406 - val_loss: 0.9937 - val_accuracy: 0.7656\n",
      "Epoch 737/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9351 - val_loss: 0.9736 - val_accuracy: 0.7719\n",
      "Epoch 738/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9390 - val_loss: 0.9993 - val_accuracy: 0.7656\n",
      "Epoch 739/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9398 - val_loss: 1.0082 - val_accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9461 - val_loss: 0.9979 - val_accuracy: 0.7594\n",
      "Epoch 741/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9414 - val_loss: 0.9841 - val_accuracy: 0.7688\n",
      "Epoch 742/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9507 - val_loss: 0.9504 - val_accuracy: 0.7875\n",
      "Epoch 743/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9445 - val_loss: 0.9561 - val_accuracy: 0.7719\n",
      "Epoch 744/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9500 - val_loss: 0.9716 - val_accuracy: 0.7625\n",
      "Epoch 745/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9437 - val_loss: 0.9717 - val_accuracy: 0.7719\n",
      "Epoch 746/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9429 - val_loss: 0.9740 - val_accuracy: 0.7750\n",
      "Epoch 747/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9453 - val_loss: 0.9487 - val_accuracy: 0.7750\n",
      "Epoch 748/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9437 - val_loss: 0.9622 - val_accuracy: 0.7844\n",
      "Epoch 749/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9492 - val_loss: 1.0129 - val_accuracy: 0.7656\n",
      "Epoch 750/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9468 - val_loss: 0.9553 - val_accuracy: 0.7750\n",
      "Epoch 751/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9445 - val_loss: 0.9677 - val_accuracy: 0.7750\n",
      "Epoch 752/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9406 - val_loss: 1.0119 - val_accuracy: 0.7750\n",
      "Epoch 753/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9445 - val_loss: 0.9754 - val_accuracy: 0.7719\n",
      "Epoch 754/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9523 - val_loss: 0.9799 - val_accuracy: 0.7625\n",
      "Epoch 755/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9515 - val_loss: 1.0149 - val_accuracy: 0.7469\n",
      "Epoch 756/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9492 - val_loss: 0.9893 - val_accuracy: 0.7875\n",
      "Epoch 757/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9382 - val_loss: 0.9941 - val_accuracy: 0.7719\n",
      "Epoch 758/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9390 - val_loss: 0.9780 - val_accuracy: 0.7656\n",
      "Epoch 759/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9468 - val_loss: 1.0292 - val_accuracy: 0.7563\n",
      "Epoch 760/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9539 - val_loss: 0.9989 - val_accuracy: 0.7688\n",
      "Epoch 761/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9554 - val_loss: 1.0149 - val_accuracy: 0.7500\n",
      "Epoch 762/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9453 - val_loss: 1.0009 - val_accuracy: 0.7812\n",
      "Epoch 763/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9437 - val_loss: 1.0121 - val_accuracy: 0.7844\n",
      "Epoch 764/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9554 - val_loss: 1.0410 - val_accuracy: 0.7688\n",
      "Epoch 765/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9523 - val_loss: 1.0060 - val_accuracy: 0.7844\n",
      "Epoch 766/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9453 - val_loss: 0.9985 - val_accuracy: 0.7719\n",
      "Epoch 767/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9531 - val_loss: 1.0124 - val_accuracy: 0.7719\n",
      "Epoch 768/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9461 - val_loss: 1.0259 - val_accuracy: 0.7781\n",
      "Epoch 769/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9461 - val_loss: 1.0082 - val_accuracy: 0.7719\n",
      "Epoch 770/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 0.9476 - val_loss: 1.0445 - val_accuracy: 0.7437\n",
      "Epoch 771/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9484 - val_loss: 1.0390 - val_accuracy: 0.7500\n",
      "Epoch 772/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9547 - val_loss: 1.0438 - val_accuracy: 0.7594\n",
      "Epoch 773/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9476 - val_loss: 1.0233 - val_accuracy: 0.7719\n",
      "Epoch 774/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.9398 - val_loss: 1.0205 - val_accuracy: 0.7844\n",
      "Epoch 775/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9492 - val_loss: 1.0779 - val_accuracy: 0.7719\n",
      "Epoch 776/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9531 - val_loss: 1.0182 - val_accuracy: 0.7781\n",
      "Epoch 777/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9468 - val_loss: 1.0106 - val_accuracy: 0.7563\n",
      "Epoch 778/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9515 - val_loss: 1.0316 - val_accuracy: 0.7750\n",
      "Epoch 779/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9507 - val_loss: 1.0198 - val_accuracy: 0.7781\n",
      "Epoch 780/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9515 - val_loss: 1.0643 - val_accuracy: 0.7719\n",
      "Epoch 781/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9523 - val_loss: 1.0789 - val_accuracy: 0.7844\n",
      "Epoch 782/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1384 - accuracy: 0.9539 - val_loss: 1.0624 - val_accuracy: 0.7594\n",
      "Epoch 783/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9414 - val_loss: 1.0597 - val_accuracy: 0.7812\n",
      "Epoch 784/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9515 - val_loss: 1.0230 - val_accuracy: 0.7719\n",
      "Epoch 785/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9461 - val_loss: 1.0836 - val_accuracy: 0.7781\n",
      "Epoch 786/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9445 - val_loss: 1.0314 - val_accuracy: 0.7875\n",
      "Epoch 787/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9445 - val_loss: 1.0591 - val_accuracy: 0.7812\n",
      "Epoch 788/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9453 - val_loss: 1.0423 - val_accuracy: 0.7781\n",
      "Epoch 789/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9445 - val_loss: 1.0230 - val_accuracy: 0.7625\n",
      "Epoch 790/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9554 - val_loss: 1.0596 - val_accuracy: 0.7719\n",
      "Epoch 791/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9453 - val_loss: 1.0221 - val_accuracy: 0.7594\n",
      "Epoch 792/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9507 - val_loss: 1.0683 - val_accuracy: 0.7563\n",
      "Epoch 793/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9531 - val_loss: 1.0741 - val_accuracy: 0.7656\n",
      "Epoch 794/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9515 - val_loss: 1.0889 - val_accuracy: 0.7594\n",
      "Epoch 795/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9570 - val_loss: 1.0729 - val_accuracy: 0.7781\n",
      "Epoch 796/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9539 - val_loss: 1.0416 - val_accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 797/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9554 - val_loss: 1.0960 - val_accuracy: 0.7688\n",
      "Epoch 798/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9562 - val_loss: 1.1075 - val_accuracy: 0.7750\n",
      "Epoch 799/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9507 - val_loss: 1.0699 - val_accuracy: 0.7750\n",
      "Epoch 800/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9523 - val_loss: 1.0705 - val_accuracy: 0.7750\n",
      "Epoch 801/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9554 - val_loss: 1.0586 - val_accuracy: 0.7750\n",
      "Epoch 802/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9562 - val_loss: 1.0828 - val_accuracy: 0.7688\n",
      "Epoch 803/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9515 - val_loss: 1.0567 - val_accuracy: 0.7563\n",
      "Epoch 804/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1413 - accuracy: 0.9453 - val_loss: 1.0935 - val_accuracy: 0.7781\n",
      "Epoch 805/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9539 - val_loss: 1.0717 - val_accuracy: 0.7563\n",
      "Epoch 806/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9609 - val_loss: 1.0815 - val_accuracy: 0.7656\n",
      "Epoch 807/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1317 - accuracy: 0.9531 - val_loss: 1.1239 - val_accuracy: 0.7563\n",
      "Epoch 808/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9484 - val_loss: 1.0653 - val_accuracy: 0.7812\n",
      "Epoch 809/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9492 - val_loss: 1.0917 - val_accuracy: 0.7750\n",
      "Epoch 810/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9445 - val_loss: 1.1339 - val_accuracy: 0.7688\n",
      "Epoch 811/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9523 - val_loss: 1.0850 - val_accuracy: 0.7625\n",
      "Epoch 812/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9507 - val_loss: 1.1093 - val_accuracy: 0.7594\n",
      "Epoch 813/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.9578 - val_loss: 1.0852 - val_accuracy: 0.7688\n",
      "Epoch 814/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1317 - accuracy: 0.9515 - val_loss: 1.0831 - val_accuracy: 0.7594\n",
      "Epoch 815/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9437 - val_loss: 1.0957 - val_accuracy: 0.7781\n",
      "Epoch 816/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1294 - accuracy: 0.9562 - val_loss: 1.1070 - val_accuracy: 0.7469\n",
      "Epoch 817/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.9500 - val_loss: 1.1447 - val_accuracy: 0.7469\n",
      "Epoch 818/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9507 - val_loss: 1.0506 - val_accuracy: 0.7625\n",
      "Epoch 819/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9547 - val_loss: 1.0735 - val_accuracy: 0.7812\n",
      "Epoch 820/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1294 - accuracy: 0.9523 - val_loss: 1.0769 - val_accuracy: 0.7750\n",
      "Epoch 821/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.9429 - val_loss: 1.1111 - val_accuracy: 0.7625\n",
      "Epoch 822/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1228 - accuracy: 0.9593 - val_loss: 1.0919 - val_accuracy: 0.7656\n",
      "Epoch 823/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9539 - val_loss: 1.1195 - val_accuracy: 0.7625\n",
      "Epoch 824/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9570 - val_loss: 1.1264 - val_accuracy: 0.7750\n",
      "Epoch 825/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9578 - val_loss: 1.1029 - val_accuracy: 0.7688\n",
      "Epoch 826/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9586 - val_loss: 1.0898 - val_accuracy: 0.7750\n",
      "Epoch 827/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9507 - val_loss: 1.1393 - val_accuracy: 0.7844\n",
      "Epoch 828/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9429 - val_loss: 1.0822 - val_accuracy: 0.7625\n",
      "Epoch 829/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9421 - val_loss: 1.1609 - val_accuracy: 0.7500\n",
      "Epoch 830/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9461 - val_loss: 1.0831 - val_accuracy: 0.7656\n",
      "Epoch 831/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9554 - val_loss: 1.1459 - val_accuracy: 0.7594\n",
      "Epoch 832/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9515 - val_loss: 1.1448 - val_accuracy: 0.7656\n",
      "Epoch 833/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1223 - accuracy: 0.9617 - val_loss: 1.1310 - val_accuracy: 0.7656\n",
      "Epoch 834/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9547 - val_loss: 1.1330 - val_accuracy: 0.7500\n",
      "Epoch 835/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9547 - val_loss: 1.1334 - val_accuracy: 0.7688\n",
      "Epoch 836/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9507 - val_loss: 1.0991 - val_accuracy: 0.7625\n",
      "Epoch 837/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9461 - val_loss: 1.0966 - val_accuracy: 0.7656\n",
      "Epoch 838/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.9492 - val_loss: 1.1407 - val_accuracy: 0.7750\n",
      "Epoch 839/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9515 - val_loss: 1.1268 - val_accuracy: 0.7563\n",
      "Epoch 840/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9554 - val_loss: 1.1675 - val_accuracy: 0.7781\n",
      "Epoch 841/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9539 - val_loss: 1.1859 - val_accuracy: 0.7563\n",
      "Epoch 842/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9281 - val_loss: 1.1160 - val_accuracy: 0.7844\n",
      "Epoch 843/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.9203 - val_loss: 1.1623 - val_accuracy: 0.7688\n",
      "Epoch 844/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9617 - val_loss: 1.1165 - val_accuracy: 0.7750\n",
      "Epoch 845/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9484 - val_loss: 1.0998 - val_accuracy: 0.7781\n",
      "Epoch 846/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9633 - val_loss: 1.1308 - val_accuracy: 0.7625\n",
      "Epoch 847/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1205 - accuracy: 0.9578 - val_loss: 1.1393 - val_accuracy: 0.7656\n",
      "Epoch 848/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1210 - accuracy: 0.9562 - val_loss: 1.1528 - val_accuracy: 0.7625\n",
      "Epoch 849/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9554 - val_loss: 1.1609 - val_accuracy: 0.7656\n",
      "Epoch 850/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9578 - val_loss: 1.1225 - val_accuracy: 0.7625\n",
      "Epoch 851/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9531 - val_loss: 1.1065 - val_accuracy: 0.7563\n",
      "Epoch 852/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9554 - val_loss: 1.1442 - val_accuracy: 0.7437\n",
      "Epoch 853/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9515 - val_loss: 1.1221 - val_accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 854/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9593 - val_loss: 1.1368 - val_accuracy: 0.7563\n",
      "Epoch 855/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9578 - val_loss: 1.1362 - val_accuracy: 0.7656\n",
      "Epoch 856/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.9547 - val_loss: 1.1279 - val_accuracy: 0.7531\n",
      "Epoch 857/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9601 - val_loss: 1.1122 - val_accuracy: 0.7625\n",
      "Epoch 858/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9586 - val_loss: 1.1045 - val_accuracy: 0.7656\n",
      "Epoch 859/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9664 - val_loss: 1.1242 - val_accuracy: 0.7688\n",
      "Epoch 860/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9593 - val_loss: 1.1427 - val_accuracy: 0.7781\n",
      "Epoch 861/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9515 - val_loss: 1.0696 - val_accuracy: 0.7688\n",
      "Epoch 862/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9453 - val_loss: 1.1096 - val_accuracy: 0.7750\n",
      "Epoch 863/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9562 - val_loss: 1.1460 - val_accuracy: 0.7625\n",
      "Epoch 864/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9515 - val_loss: 1.1511 - val_accuracy: 0.7656\n",
      "Epoch 865/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9523 - val_loss: 1.1186 - val_accuracy: 0.7688\n",
      "Epoch 866/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9578 - val_loss: 1.1784 - val_accuracy: 0.7688\n",
      "Epoch 867/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9578 - val_loss: 1.1237 - val_accuracy: 0.7688\n",
      "Epoch 868/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9500 - val_loss: 1.1351 - val_accuracy: 0.7625\n",
      "Epoch 869/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9562 - val_loss: 1.1294 - val_accuracy: 0.7594\n",
      "Epoch 870/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9609 - val_loss: 1.1414 - val_accuracy: 0.7531\n",
      "Epoch 871/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1224 - accuracy: 0.9570 - val_loss: 1.1131 - val_accuracy: 0.7688\n",
      "Epoch 872/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9586 - val_loss: 1.1429 - val_accuracy: 0.7500\n",
      "Epoch 873/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1164 - accuracy: 0.9547 - val_loss: 1.1574 - val_accuracy: 0.7594\n",
      "Epoch 874/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9586 - val_loss: 1.1326 - val_accuracy: 0.7719\n",
      "Epoch 875/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.9640 - val_loss: 1.1462 - val_accuracy: 0.7594\n",
      "Epoch 876/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9554 - val_loss: 1.1466 - val_accuracy: 0.7594\n",
      "Epoch 877/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.9593 - val_loss: 1.1523 - val_accuracy: 0.7625\n",
      "Epoch 878/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9640 - val_loss: 1.1504 - val_accuracy: 0.7688\n",
      "Epoch 879/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9570 - val_loss: 1.1610 - val_accuracy: 0.7625\n",
      "Epoch 880/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9523 - val_loss: 1.1289 - val_accuracy: 0.7625\n",
      "Epoch 881/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9601 - val_loss: 1.1424 - val_accuracy: 0.7750\n",
      "Epoch 882/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9633 - val_loss: 1.1555 - val_accuracy: 0.7719\n",
      "Epoch 883/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1232 - accuracy: 0.9578 - val_loss: 1.1481 - val_accuracy: 0.7750\n",
      "Epoch 884/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9570 - val_loss: 1.1583 - val_accuracy: 0.7500\n",
      "Epoch 885/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9601 - val_loss: 1.1879 - val_accuracy: 0.7531\n",
      "Epoch 886/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9586 - val_loss: 1.1734 - val_accuracy: 0.7625\n",
      "Epoch 887/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9656 - val_loss: 1.1684 - val_accuracy: 0.7656\n",
      "Epoch 888/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9625 - val_loss: 1.1785 - val_accuracy: 0.7625\n",
      "Epoch 889/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9679 - val_loss: 1.1632 - val_accuracy: 0.7688\n",
      "Epoch 890/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 0.95 - 0s 3ms/step - loss: 0.1212 - accuracy: 0.9593 - val_loss: 1.1773 - val_accuracy: 0.7656\n",
      "Epoch 891/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9601 - val_loss: 1.1915 - val_accuracy: 0.7688\n",
      "Epoch 892/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9601 - val_loss: 1.1684 - val_accuracy: 0.7656\n",
      "Epoch 893/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9547 - val_loss: 1.1757 - val_accuracy: 0.7531\n",
      "Epoch 894/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9547 - val_loss: 1.1964 - val_accuracy: 0.7688\n",
      "Epoch 895/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9578 - val_loss: 1.1674 - val_accuracy: 0.7625\n",
      "Epoch 896/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9656 - val_loss: 1.1885 - val_accuracy: 0.7750\n",
      "Epoch 897/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9609 - val_loss: 1.1802 - val_accuracy: 0.7688\n",
      "Epoch 898/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9609 - val_loss: 1.2185 - val_accuracy: 0.7719\n",
      "Epoch 899/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9570 - val_loss: 1.1727 - val_accuracy: 0.7719\n",
      "Epoch 900/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9609 - val_loss: 1.1809 - val_accuracy: 0.7719\n",
      "Epoch 901/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9648 - val_loss: 1.2115 - val_accuracy: 0.7625\n",
      "Epoch 902/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9523 - val_loss: 1.1769 - val_accuracy: 0.7531\n",
      "Epoch 903/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9601 - val_loss: 1.1563 - val_accuracy: 0.7688\n",
      "Epoch 904/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.9648 - val_loss: 1.2682 - val_accuracy: 0.7531\n",
      "Epoch 905/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1280 - accuracy: 0.9562 - val_loss: 1.2544 - val_accuracy: 0.7750\n",
      "Epoch 906/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9648 - val_loss: 1.1532 - val_accuracy: 0.7812\n",
      "Epoch 907/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.9633 - val_loss: 1.1995 - val_accuracy: 0.7625\n",
      "Epoch 908/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.96 - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9531 - val_loss: 1.1976 - val_accuracy: 0.7563\n",
      "Epoch 909/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.9640 - val_loss: 1.2107 - val_accuracy: 0.7656\n",
      "Epoch 910/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9476 - val_loss: 1.1980 - val_accuracy: 0.7781\n",
      "Epoch 911/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9523 - val_loss: 1.2110 - val_accuracy: 0.7531\n",
      "Epoch 912/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9609 - val_loss: 1.2151 - val_accuracy: 0.7563\n",
      "Epoch 913/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9633 - val_loss: 1.1735 - val_accuracy: 0.7688\n",
      "Epoch 914/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9578 - val_loss: 1.1847 - val_accuracy: 0.7781\n",
      "Epoch 915/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1230 - accuracy: 0.9554 - val_loss: 1.2290 - val_accuracy: 0.7594\n",
      "Epoch 916/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9593 - val_loss: 1.1851 - val_accuracy: 0.7656\n",
      "Epoch 917/1000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.97 - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9664 - val_loss: 1.2053 - val_accuracy: 0.7594\n",
      "Epoch 918/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1184 - accuracy: 0.9570 - val_loss: 1.2082 - val_accuracy: 0.7719\n",
      "Epoch 919/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9640 - val_loss: 1.2624 - val_accuracy: 0.7563\n",
      "Epoch 920/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9601 - val_loss: 1.1968 - val_accuracy: 0.7500\n",
      "Epoch 921/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9562 - val_loss: 1.2461 - val_accuracy: 0.7781\n",
      "Epoch 922/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9601 - val_loss: 1.2212 - val_accuracy: 0.7500\n",
      "Epoch 923/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9679 - val_loss: 1.2212 - val_accuracy: 0.7656\n",
      "Epoch 924/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9687 - val_loss: 1.2272 - val_accuracy: 0.7500\n",
      "Epoch 925/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9593 - val_loss: 1.2023 - val_accuracy: 0.7688\n",
      "Epoch 926/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9695 - val_loss: 1.2135 - val_accuracy: 0.7656\n",
      "Epoch 927/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9586 - val_loss: 1.2227 - val_accuracy: 0.7656\n",
      "Epoch 928/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.9640 - val_loss: 1.2185 - val_accuracy: 0.7563\n",
      "Epoch 929/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9617 - val_loss: 1.3151 - val_accuracy: 0.7312\n",
      "Epoch 930/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9500 - val_loss: 1.2686 - val_accuracy: 0.7656\n",
      "Epoch 931/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9609 - val_loss: 1.2542 - val_accuracy: 0.7563\n",
      "Epoch 932/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1169 - accuracy: 0.9515 - val_loss: 1.2267 - val_accuracy: 0.7625\n",
      "Epoch 933/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9492 - val_loss: 1.2448 - val_accuracy: 0.7656\n",
      "Epoch 934/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.9547 - val_loss: 1.2700 - val_accuracy: 0.7719\n",
      "Epoch 935/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9617 - val_loss: 1.2648 - val_accuracy: 0.7625\n",
      "Epoch 936/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9625 - val_loss: 1.2533 - val_accuracy: 0.7750\n",
      "Epoch 937/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9672 - val_loss: 1.2473 - val_accuracy: 0.7688\n",
      "Epoch 938/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9586 - val_loss: 1.2370 - val_accuracy: 0.7750\n",
      "Epoch 939/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9648 - val_loss: 1.2752 - val_accuracy: 0.7812\n",
      "Epoch 940/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9578 - val_loss: 1.2432 - val_accuracy: 0.7656\n",
      "Epoch 941/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9601 - val_loss: 1.3241 - val_accuracy: 0.7469\n",
      "Epoch 942/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9609 - val_loss: 1.2074 - val_accuracy: 0.7625\n",
      "Epoch 943/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9656 - val_loss: 1.2704 - val_accuracy: 0.7656\n",
      "Epoch 944/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9593 - val_loss: 1.2837 - val_accuracy: 0.7625\n",
      "Epoch 945/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9625 - val_loss: 1.2779 - val_accuracy: 0.7469\n",
      "Epoch 946/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.9625 - val_loss: 1.3089 - val_accuracy: 0.7500\n",
      "Epoch 947/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9679 - val_loss: 1.2620 - val_accuracy: 0.7688\n",
      "Epoch 948/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9679 - val_loss: 1.2553 - val_accuracy: 0.7688\n",
      "Epoch 949/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9640 - val_loss: 1.2264 - val_accuracy: 0.7531\n",
      "Epoch 950/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9609 - val_loss: 1.2883 - val_accuracy: 0.7594\n",
      "Epoch 951/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9570 - val_loss: 1.2285 - val_accuracy: 0.7594\n",
      "Epoch 952/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9679 - val_loss: 1.2787 - val_accuracy: 0.7750\n",
      "Epoch 953/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9711 - val_loss: 1.2581 - val_accuracy: 0.7531\n",
      "Epoch 954/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9719 - val_loss: 1.3151 - val_accuracy: 0.7750\n",
      "Epoch 955/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9656 - val_loss: 1.2594 - val_accuracy: 0.7750\n",
      "Epoch 956/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9726 - val_loss: 1.2917 - val_accuracy: 0.7719\n",
      "Epoch 957/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9593 - val_loss: 1.2673 - val_accuracy: 0.7500\n",
      "Epoch 958/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9679 - val_loss: 1.3157 - val_accuracy: 0.7719\n",
      "Epoch 959/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9570 - val_loss: 1.2655 - val_accuracy: 0.7750\n",
      "Epoch 960/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9640 - val_loss: 1.2840 - val_accuracy: 0.7656\n",
      "Epoch 961/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.9679 - val_loss: 1.3027 - val_accuracy: 0.7750\n",
      "Epoch 962/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9593 - val_loss: 1.2981 - val_accuracy: 0.7406\n",
      "Epoch 963/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9672 - val_loss: 1.3261 - val_accuracy: 0.7781\n",
      "Epoch 964/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.9640 - val_loss: 1.2698 - val_accuracy: 0.7563\n",
      "Epoch 965/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9719 - val_loss: 1.3338 - val_accuracy: 0.7469\n",
      "Epoch 966/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9656 - val_loss: 1.3560 - val_accuracy: 0.7531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 967/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9625 - val_loss: 1.3455 - val_accuracy: 0.7656\n",
      "Epoch 968/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9578 - val_loss: 1.3768 - val_accuracy: 0.7500\n",
      "Epoch 969/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9617 - val_loss: 1.2319 - val_accuracy: 0.7688\n",
      "Epoch 970/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9554 - val_loss: 1.3616 - val_accuracy: 0.7719\n",
      "Epoch 971/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9593 - val_loss: 1.5189 - val_accuracy: 0.7563\n",
      "Epoch 972/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9500 - val_loss: 1.3792 - val_accuracy: 0.7500\n",
      "Epoch 973/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9711 - val_loss: 1.3400 - val_accuracy: 0.7688\n",
      "Epoch 974/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9672 - val_loss: 1.3932 - val_accuracy: 0.7594\n",
      "Epoch 975/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9554 - val_loss: 1.3504 - val_accuracy: 0.7563\n",
      "Epoch 976/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9547 - val_loss: 1.3772 - val_accuracy: 0.7812\n",
      "Epoch 977/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9726 - val_loss: 1.3139 - val_accuracy: 0.7750\n",
      "Epoch 978/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.9695 - val_loss: 1.3451 - val_accuracy: 0.7719\n",
      "Epoch 979/1000\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9656 - val_loss: 1.3135 - val_accuracy: 0.7625\n",
      "Epoch 980/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9679 - val_loss: 1.3705 - val_accuracy: 0.7812\n",
      "Epoch 981/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9687 - val_loss: 1.3403 - val_accuracy: 0.7531\n",
      "Epoch 982/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9734 - val_loss: 1.3226 - val_accuracy: 0.7500\n",
      "Epoch 983/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9711 - val_loss: 1.3358 - val_accuracy: 0.7656\n",
      "Epoch 984/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9703 - val_loss: 1.3690 - val_accuracy: 0.7781\n",
      "Epoch 985/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9679 - val_loss: 1.3427 - val_accuracy: 0.7688\n",
      "Epoch 986/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9726 - val_loss: 1.3467 - val_accuracy: 0.7563\n",
      "Epoch 987/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 0.9679 - val_loss: 1.3379 - val_accuracy: 0.7625\n",
      "Epoch 988/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9672 - val_loss: 1.3128 - val_accuracy: 0.7563\n",
      "Epoch 989/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9664 - val_loss: 1.3912 - val_accuracy: 0.7406\n",
      "Epoch 990/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9679 - val_loss: 1.3668 - val_accuracy: 0.7625\n",
      "Epoch 991/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9687 - val_loss: 1.3723 - val_accuracy: 0.7656\n",
      "Epoch 992/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9648 - val_loss: 1.3412 - val_accuracy: 0.7750\n",
      "Epoch 993/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.9593 - val_loss: 1.3710 - val_accuracy: 0.7719\n",
      "Epoch 994/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9656 - val_loss: 1.3882 - val_accuracy: 0.7656\n",
      "Epoch 995/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9726 - val_loss: 1.3857 - val_accuracy: 0.7688\n",
      "Epoch 996/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9703 - val_loss: 1.3608 - val_accuracy: 0.7531\n",
      "Epoch 997/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9515 - val_loss: 1.4463 - val_accuracy: 0.7531\n",
      "Epoch 998/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9687 - val_loss: 1.3720 - val_accuracy: 0.7719\n",
      "Epoch 999/1000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9640 - val_loss: 1.3820 - val_accuracy: 0.7594\n",
      "Epoch 1000/1000\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9711 - val_loss: 1.3915 - val_accuracy: 0.7719\n"
     ]
    }
   ],
   "source": [
    "#Compilando a RNA\n",
    "rna.compile(optimizer = tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = rna.fit(X_train, Y_train, epochs=1000, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d30680c",
   "metadata": {},
   "source": [
    "## Step 20\n",
    "\n",
    "Plotagem dos gráficos da função de custo/exatidão x épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "7eddac4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fazer gráfico\n",
    "# Recupera hostorico do treinamento\n",
    "history_dict = history.history\n",
    "\n",
    "# Salva custo e exatidão em vetores\n",
    "custo = history_dict['loss']\n",
    "exatidao = history_dict['accuracy']\n",
    "val_custo = history_dict['val_loss']\n",
    "val_exatidao = history_dict['val_accuracy']\n",
    "\n",
    "# Cria vetor de épocas\n",
    "epocas = range(1, len(custo) + 1)\n",
    "\n",
    "# Gráfico do custo em funçaõ das épocas\n",
    "plt.plot(epocas, custo, 'b', label='Dados treinamento')\n",
    "plt.plot(epocas, val_custo, 'r', label='Dados validação')\n",
    "plt.title('Valor da função de custo')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Custo')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico da exatidão em função das épocas\n",
    "plt.plot(epocas, exatidao, 'b', label='Dados treinamento')\n",
    "plt.plot(epocas, val_exatidao, 'r', label='Dadosvalidação')\n",
    "plt.title('Valor da exatidão')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Exatidão')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024cd3c5",
   "metadata": {},
   "source": [
    "## Step 21\n",
    "\n",
    "Avaliação da RNA. O comando '.evaluate' permite avaliar a RNA para os dados de treinamento (X_train, Y_train) e teste (X_test, Y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "fd9ed494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.9703\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3915 - accuracy: 0.7719\n"
     ]
    }
   ],
   "source": [
    "#avaliar os dados\n",
    "cm_train = rna.evaluate(X_train, Y_train)\n",
    "cm_test = rna.evaluate(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062265ed",
   "metadata": {},
   "source": [
    "## Step 22\n",
    "\n",
    "Calculo da previsão da RNA pela função '.predict' e impressão dos dados reais x previstos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "ec3dbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo das classes previstas\n",
    "y_prev = rna.predict(X_test)\n",
    "classes = np.round(y_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "93bd3f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfico das classes reais e previstas\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(Y_test, 'ro', label='Classes reais')\n",
    "plt.plot(classes, 'bo', label='Classes previstas')\n",
    "plt.title('Classes reais e previstas')\n",
    "plt.xlabel('Exemplos')\n",
    "plt.ylabel('Classes')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d8b03",
   "metadata": {},
   "source": [
    "## Step 23\n",
    "\n",
    "Verificação da previsão. Y_test[1:5] mostra a saída real dos primeiros 5 elementos do Data frame. \n",
    "previsao = rna.predict(X_test[1:5])calcula a previsão de saída desses mesmos dados e realiza a impressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f56b565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d7e29eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999223 ],\n",
       "       [0.99816585],\n",
       "       [0.9959339 ],\n",
       "       [0.9780502 ]], dtype=float32)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao = rna.predict(X_test[1:5])\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b44940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
